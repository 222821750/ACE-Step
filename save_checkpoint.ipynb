{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3367140/2080906558.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint_path = \"/root/sag_train/checkpoints/aceflow3_250401/epoch=22-step=460k_pretrained_ft_240k_small_repa.ckpt\"\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['resampler_mert.kernel', 'resampler_mhubert.kernel', 'vae.mel_transform.spectrogram.window', 'vae.mel_transform.mel_scale.fb', 'vae.vocoder.mel_transform.spectrogram.window', 'vae.vocoder.mel_transform.mel_scale.fb', 'vae.resampler.kernel', 'lyric_processor.lyric_text_model.shared.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.0.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.1.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.2.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.3.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.4.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.5.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.6.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.7.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.8.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.9.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.10.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.0.SelfAttention.q.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.0.SelfAttention.k.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.0.SelfAttention.v.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.0.SelfAttention.o.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.0.SelfAttention.relative_attention_bias.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.0.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.1.DenseReluDense.wi_0.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'lyric_processor.lyric_text_model.encoder.block.11.layer.1.layer_norm.weight', 'lyric_processor.lyric_text_model.encoder.final_layer_norm.weight', 'mert_model.masked_spec_embed', 'mert_model.feature_extractor.conv_layers.0.conv.weight', 'mert_model.feature_extractor.conv_layers.0.layer_norm.weight', 'mert_model.feature_extractor.conv_layers.0.layer_norm.bias', 'mert_model.feature_extractor.conv_layers.1.conv.weight', 'mert_model.feature_extractor.conv_layers.2.conv.weight', 'mert_model.feature_extractor.conv_layers.3.conv.weight', 'mert_model.feature_extractor.conv_layers.4.conv.weight', 'mert_model.feature_extractor.conv_layers.5.conv.weight', 'mert_model.feature_extractor.conv_layers.6.conv.weight', 'mert_model.feature_projection.layer_norm.weight', 'mert_model.feature_projection.layer_norm.bias', 'mert_model.feature_projection.projection.weight', 'mert_model.feature_projection.projection.bias', 'mert_model.encoder.pos_conv_embed.conv.bias', 'mert_model.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'mert_model.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'mert_model.encoder.layer_norm.weight', 'mert_model.encoder.layer_norm.bias', 'mert_model.encoder.layers.0.attention.k_proj.weight', 'mert_model.encoder.layers.0.attention.k_proj.bias', 'mert_model.encoder.layers.0.attention.v_proj.weight', 'mert_model.encoder.layers.0.attention.v_proj.bias', 'mert_model.encoder.layers.0.attention.q_proj.weight', 'mert_model.encoder.layers.0.attention.q_proj.bias', 'mert_model.encoder.layers.0.attention.out_proj.weight', 'mert_model.encoder.layers.0.attention.out_proj.bias', 'mert_model.encoder.layers.0.layer_norm.weight', 'mert_model.encoder.layers.0.layer_norm.bias', 'mert_model.encoder.layers.0.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.0.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.0.feed_forward.output_dense.weight', 'mert_model.encoder.layers.0.feed_forward.output_dense.bias', 'mert_model.encoder.layers.0.final_layer_norm.weight', 'mert_model.encoder.layers.0.final_layer_norm.bias', 'mert_model.encoder.layers.1.attention.k_proj.weight', 'mert_model.encoder.layers.1.attention.k_proj.bias', 'mert_model.encoder.layers.1.attention.v_proj.weight', 'mert_model.encoder.layers.1.attention.v_proj.bias', 'mert_model.encoder.layers.1.attention.q_proj.weight', 'mert_model.encoder.layers.1.attention.q_proj.bias', 'mert_model.encoder.layers.1.attention.out_proj.weight', 'mert_model.encoder.layers.1.attention.out_proj.bias', 'mert_model.encoder.layers.1.layer_norm.weight', 'mert_model.encoder.layers.1.layer_norm.bias', 'mert_model.encoder.layers.1.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.1.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.1.feed_forward.output_dense.weight', 'mert_model.encoder.layers.1.feed_forward.output_dense.bias', 'mert_model.encoder.layers.1.final_layer_norm.weight', 'mert_model.encoder.layers.1.final_layer_norm.bias', 'mert_model.encoder.layers.2.attention.k_proj.weight', 'mert_model.encoder.layers.2.attention.k_proj.bias', 'mert_model.encoder.layers.2.attention.v_proj.weight', 'mert_model.encoder.layers.2.attention.v_proj.bias', 'mert_model.encoder.layers.2.attention.q_proj.weight', 'mert_model.encoder.layers.2.attention.q_proj.bias', 'mert_model.encoder.layers.2.attention.out_proj.weight', 'mert_model.encoder.layers.2.attention.out_proj.bias', 'mert_model.encoder.layers.2.layer_norm.weight', 'mert_model.encoder.layers.2.layer_norm.bias', 'mert_model.encoder.layers.2.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.2.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.2.feed_forward.output_dense.weight', 'mert_model.encoder.layers.2.feed_forward.output_dense.bias', 'mert_model.encoder.layers.2.final_layer_norm.weight', 'mert_model.encoder.layers.2.final_layer_norm.bias', 'mert_model.encoder.layers.3.attention.k_proj.weight', 'mert_model.encoder.layers.3.attention.k_proj.bias', 'mert_model.encoder.layers.3.attention.v_proj.weight', 'mert_model.encoder.layers.3.attention.v_proj.bias', 'mert_model.encoder.layers.3.attention.q_proj.weight', 'mert_model.encoder.layers.3.attention.q_proj.bias', 'mert_model.encoder.layers.3.attention.out_proj.weight', 'mert_model.encoder.layers.3.attention.out_proj.bias', 'mert_model.encoder.layers.3.layer_norm.weight', 'mert_model.encoder.layers.3.layer_norm.bias', 'mert_model.encoder.layers.3.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.3.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.3.feed_forward.output_dense.weight', 'mert_model.encoder.layers.3.feed_forward.output_dense.bias', 'mert_model.encoder.layers.3.final_layer_norm.weight', 'mert_model.encoder.layers.3.final_layer_norm.bias', 'mert_model.encoder.layers.4.attention.k_proj.weight', 'mert_model.encoder.layers.4.attention.k_proj.bias', 'mert_model.encoder.layers.4.attention.v_proj.weight', 'mert_model.encoder.layers.4.attention.v_proj.bias', 'mert_model.encoder.layers.4.attention.q_proj.weight', 'mert_model.encoder.layers.4.attention.q_proj.bias', 'mert_model.encoder.layers.4.attention.out_proj.weight', 'mert_model.encoder.layers.4.attention.out_proj.bias', 'mert_model.encoder.layers.4.layer_norm.weight', 'mert_model.encoder.layers.4.layer_norm.bias', 'mert_model.encoder.layers.4.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.4.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.4.feed_forward.output_dense.weight', 'mert_model.encoder.layers.4.feed_forward.output_dense.bias', 'mert_model.encoder.layers.4.final_layer_norm.weight', 'mert_model.encoder.layers.4.final_layer_norm.bias', 'mert_model.encoder.layers.5.attention.k_proj.weight', 'mert_model.encoder.layers.5.attention.k_proj.bias', 'mert_model.encoder.layers.5.attention.v_proj.weight', 'mert_model.encoder.layers.5.attention.v_proj.bias', 'mert_model.encoder.layers.5.attention.q_proj.weight', 'mert_model.encoder.layers.5.attention.q_proj.bias', 'mert_model.encoder.layers.5.attention.out_proj.weight', 'mert_model.encoder.layers.5.attention.out_proj.bias', 'mert_model.encoder.layers.5.layer_norm.weight', 'mert_model.encoder.layers.5.layer_norm.bias', 'mert_model.encoder.layers.5.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.5.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.5.feed_forward.output_dense.weight', 'mert_model.encoder.layers.5.feed_forward.output_dense.bias', 'mert_model.encoder.layers.5.final_layer_norm.weight', 'mert_model.encoder.layers.5.final_layer_norm.bias', 'mert_model.encoder.layers.6.attention.k_proj.weight', 'mert_model.encoder.layers.6.attention.k_proj.bias', 'mert_model.encoder.layers.6.attention.v_proj.weight', 'mert_model.encoder.layers.6.attention.v_proj.bias', 'mert_model.encoder.layers.6.attention.q_proj.weight', 'mert_model.encoder.layers.6.attention.q_proj.bias', 'mert_model.encoder.layers.6.attention.out_proj.weight', 'mert_model.encoder.layers.6.attention.out_proj.bias', 'mert_model.encoder.layers.6.layer_norm.weight', 'mert_model.encoder.layers.6.layer_norm.bias', 'mert_model.encoder.layers.6.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.6.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.6.feed_forward.output_dense.weight', 'mert_model.encoder.layers.6.feed_forward.output_dense.bias', 'mert_model.encoder.layers.6.final_layer_norm.weight', 'mert_model.encoder.layers.6.final_layer_norm.bias', 'mert_model.encoder.layers.7.attention.k_proj.weight', 'mert_model.encoder.layers.7.attention.k_proj.bias', 'mert_model.encoder.layers.7.attention.v_proj.weight', 'mert_model.encoder.layers.7.attention.v_proj.bias', 'mert_model.encoder.layers.7.attention.q_proj.weight', 'mert_model.encoder.layers.7.attention.q_proj.bias', 'mert_model.encoder.layers.7.attention.out_proj.weight', 'mert_model.encoder.layers.7.attention.out_proj.bias', 'mert_model.encoder.layers.7.layer_norm.weight', 'mert_model.encoder.layers.7.layer_norm.bias', 'mert_model.encoder.layers.7.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.7.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.7.feed_forward.output_dense.weight', 'mert_model.encoder.layers.7.feed_forward.output_dense.bias', 'mert_model.encoder.layers.7.final_layer_norm.weight', 'mert_model.encoder.layers.7.final_layer_norm.bias', 'mert_model.encoder.layers.8.attention.k_proj.weight', 'mert_model.encoder.layers.8.attention.k_proj.bias', 'mert_model.encoder.layers.8.attention.v_proj.weight', 'mert_model.encoder.layers.8.attention.v_proj.bias', 'mert_model.encoder.layers.8.attention.q_proj.weight', 'mert_model.encoder.layers.8.attention.q_proj.bias', 'mert_model.encoder.layers.8.attention.out_proj.weight', 'mert_model.encoder.layers.8.attention.out_proj.bias', 'mert_model.encoder.layers.8.layer_norm.weight', 'mert_model.encoder.layers.8.layer_norm.bias', 'mert_model.encoder.layers.8.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.8.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.8.feed_forward.output_dense.weight', 'mert_model.encoder.layers.8.feed_forward.output_dense.bias', 'mert_model.encoder.layers.8.final_layer_norm.weight', 'mert_model.encoder.layers.8.final_layer_norm.bias', 'mert_model.encoder.layers.9.attention.k_proj.weight', 'mert_model.encoder.layers.9.attention.k_proj.bias', 'mert_model.encoder.layers.9.attention.v_proj.weight', 'mert_model.encoder.layers.9.attention.v_proj.bias', 'mert_model.encoder.layers.9.attention.q_proj.weight', 'mert_model.encoder.layers.9.attention.q_proj.bias', 'mert_model.encoder.layers.9.attention.out_proj.weight', 'mert_model.encoder.layers.9.attention.out_proj.bias', 'mert_model.encoder.layers.9.layer_norm.weight', 'mert_model.encoder.layers.9.layer_norm.bias', 'mert_model.encoder.layers.9.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.9.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.9.feed_forward.output_dense.weight', 'mert_model.encoder.layers.9.feed_forward.output_dense.bias', 'mert_model.encoder.layers.9.final_layer_norm.weight', 'mert_model.encoder.layers.9.final_layer_norm.bias', 'mert_model.encoder.layers.10.attention.k_proj.weight', 'mert_model.encoder.layers.10.attention.k_proj.bias', 'mert_model.encoder.layers.10.attention.v_proj.weight', 'mert_model.encoder.layers.10.attention.v_proj.bias', 'mert_model.encoder.layers.10.attention.q_proj.weight', 'mert_model.encoder.layers.10.attention.q_proj.bias', 'mert_model.encoder.layers.10.attention.out_proj.weight', 'mert_model.encoder.layers.10.attention.out_proj.bias', 'mert_model.encoder.layers.10.layer_norm.weight', 'mert_model.encoder.layers.10.layer_norm.bias', 'mert_model.encoder.layers.10.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.10.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.10.feed_forward.output_dense.weight', 'mert_model.encoder.layers.10.feed_forward.output_dense.bias', 'mert_model.encoder.layers.10.final_layer_norm.weight', 'mert_model.encoder.layers.10.final_layer_norm.bias', 'mert_model.encoder.layers.11.attention.k_proj.weight', 'mert_model.encoder.layers.11.attention.k_proj.bias', 'mert_model.encoder.layers.11.attention.v_proj.weight', 'mert_model.encoder.layers.11.attention.v_proj.bias', 'mert_model.encoder.layers.11.attention.q_proj.weight', 'mert_model.encoder.layers.11.attention.q_proj.bias', 'mert_model.encoder.layers.11.attention.out_proj.weight', 'mert_model.encoder.layers.11.attention.out_proj.bias', 'mert_model.encoder.layers.11.layer_norm.weight', 'mert_model.encoder.layers.11.layer_norm.bias', 'mert_model.encoder.layers.11.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.11.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.11.feed_forward.output_dense.weight', 'mert_model.encoder.layers.11.feed_forward.output_dense.bias', 'mert_model.encoder.layers.11.final_layer_norm.weight', 'mert_model.encoder.layers.11.final_layer_norm.bias', 'mert_model.encoder.layers.12.attention.k_proj.weight', 'mert_model.encoder.layers.12.attention.k_proj.bias', 'mert_model.encoder.layers.12.attention.v_proj.weight', 'mert_model.encoder.layers.12.attention.v_proj.bias', 'mert_model.encoder.layers.12.attention.q_proj.weight', 'mert_model.encoder.layers.12.attention.q_proj.bias', 'mert_model.encoder.layers.12.attention.out_proj.weight', 'mert_model.encoder.layers.12.attention.out_proj.bias', 'mert_model.encoder.layers.12.layer_norm.weight', 'mert_model.encoder.layers.12.layer_norm.bias', 'mert_model.encoder.layers.12.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.12.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.12.feed_forward.output_dense.weight', 'mert_model.encoder.layers.12.feed_forward.output_dense.bias', 'mert_model.encoder.layers.12.final_layer_norm.weight', 'mert_model.encoder.layers.12.final_layer_norm.bias', 'mert_model.encoder.layers.13.attention.k_proj.weight', 'mert_model.encoder.layers.13.attention.k_proj.bias', 'mert_model.encoder.layers.13.attention.v_proj.weight', 'mert_model.encoder.layers.13.attention.v_proj.bias', 'mert_model.encoder.layers.13.attention.q_proj.weight', 'mert_model.encoder.layers.13.attention.q_proj.bias', 'mert_model.encoder.layers.13.attention.out_proj.weight', 'mert_model.encoder.layers.13.attention.out_proj.bias', 'mert_model.encoder.layers.13.layer_norm.weight', 'mert_model.encoder.layers.13.layer_norm.bias', 'mert_model.encoder.layers.13.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.13.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.13.feed_forward.output_dense.weight', 'mert_model.encoder.layers.13.feed_forward.output_dense.bias', 'mert_model.encoder.layers.13.final_layer_norm.weight', 'mert_model.encoder.layers.13.final_layer_norm.bias', 'mert_model.encoder.layers.14.attention.k_proj.weight', 'mert_model.encoder.layers.14.attention.k_proj.bias', 'mert_model.encoder.layers.14.attention.v_proj.weight', 'mert_model.encoder.layers.14.attention.v_proj.bias', 'mert_model.encoder.layers.14.attention.q_proj.weight', 'mert_model.encoder.layers.14.attention.q_proj.bias', 'mert_model.encoder.layers.14.attention.out_proj.weight', 'mert_model.encoder.layers.14.attention.out_proj.bias', 'mert_model.encoder.layers.14.layer_norm.weight', 'mert_model.encoder.layers.14.layer_norm.bias', 'mert_model.encoder.layers.14.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.14.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.14.feed_forward.output_dense.weight', 'mert_model.encoder.layers.14.feed_forward.output_dense.bias', 'mert_model.encoder.layers.14.final_layer_norm.weight', 'mert_model.encoder.layers.14.final_layer_norm.bias', 'mert_model.encoder.layers.15.attention.k_proj.weight', 'mert_model.encoder.layers.15.attention.k_proj.bias', 'mert_model.encoder.layers.15.attention.v_proj.weight', 'mert_model.encoder.layers.15.attention.v_proj.bias', 'mert_model.encoder.layers.15.attention.q_proj.weight', 'mert_model.encoder.layers.15.attention.q_proj.bias', 'mert_model.encoder.layers.15.attention.out_proj.weight', 'mert_model.encoder.layers.15.attention.out_proj.bias', 'mert_model.encoder.layers.15.layer_norm.weight', 'mert_model.encoder.layers.15.layer_norm.bias', 'mert_model.encoder.layers.15.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.15.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.15.feed_forward.output_dense.weight', 'mert_model.encoder.layers.15.feed_forward.output_dense.bias', 'mert_model.encoder.layers.15.final_layer_norm.weight', 'mert_model.encoder.layers.15.final_layer_norm.bias', 'mert_model.encoder.layers.16.attention.k_proj.weight', 'mert_model.encoder.layers.16.attention.k_proj.bias', 'mert_model.encoder.layers.16.attention.v_proj.weight', 'mert_model.encoder.layers.16.attention.v_proj.bias', 'mert_model.encoder.layers.16.attention.q_proj.weight', 'mert_model.encoder.layers.16.attention.q_proj.bias', 'mert_model.encoder.layers.16.attention.out_proj.weight', 'mert_model.encoder.layers.16.attention.out_proj.bias', 'mert_model.encoder.layers.16.layer_norm.weight', 'mert_model.encoder.layers.16.layer_norm.bias', 'mert_model.encoder.layers.16.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.16.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.16.feed_forward.output_dense.weight', 'mert_model.encoder.layers.16.feed_forward.output_dense.bias', 'mert_model.encoder.layers.16.final_layer_norm.weight', 'mert_model.encoder.layers.16.final_layer_norm.bias', 'mert_model.encoder.layers.17.attention.k_proj.weight', 'mert_model.encoder.layers.17.attention.k_proj.bias', 'mert_model.encoder.layers.17.attention.v_proj.weight', 'mert_model.encoder.layers.17.attention.v_proj.bias', 'mert_model.encoder.layers.17.attention.q_proj.weight', 'mert_model.encoder.layers.17.attention.q_proj.bias', 'mert_model.encoder.layers.17.attention.out_proj.weight', 'mert_model.encoder.layers.17.attention.out_proj.bias', 'mert_model.encoder.layers.17.layer_norm.weight', 'mert_model.encoder.layers.17.layer_norm.bias', 'mert_model.encoder.layers.17.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.17.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.17.feed_forward.output_dense.weight', 'mert_model.encoder.layers.17.feed_forward.output_dense.bias', 'mert_model.encoder.layers.17.final_layer_norm.weight', 'mert_model.encoder.layers.17.final_layer_norm.bias', 'mert_model.encoder.layers.18.attention.k_proj.weight', 'mert_model.encoder.layers.18.attention.k_proj.bias', 'mert_model.encoder.layers.18.attention.v_proj.weight', 'mert_model.encoder.layers.18.attention.v_proj.bias', 'mert_model.encoder.layers.18.attention.q_proj.weight', 'mert_model.encoder.layers.18.attention.q_proj.bias', 'mert_model.encoder.layers.18.attention.out_proj.weight', 'mert_model.encoder.layers.18.attention.out_proj.bias', 'mert_model.encoder.layers.18.layer_norm.weight', 'mert_model.encoder.layers.18.layer_norm.bias', 'mert_model.encoder.layers.18.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.18.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.18.feed_forward.output_dense.weight', 'mert_model.encoder.layers.18.feed_forward.output_dense.bias', 'mert_model.encoder.layers.18.final_layer_norm.weight', 'mert_model.encoder.layers.18.final_layer_norm.bias', 'mert_model.encoder.layers.19.attention.k_proj.weight', 'mert_model.encoder.layers.19.attention.k_proj.bias', 'mert_model.encoder.layers.19.attention.v_proj.weight', 'mert_model.encoder.layers.19.attention.v_proj.bias', 'mert_model.encoder.layers.19.attention.q_proj.weight', 'mert_model.encoder.layers.19.attention.q_proj.bias', 'mert_model.encoder.layers.19.attention.out_proj.weight', 'mert_model.encoder.layers.19.attention.out_proj.bias', 'mert_model.encoder.layers.19.layer_norm.weight', 'mert_model.encoder.layers.19.layer_norm.bias', 'mert_model.encoder.layers.19.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.19.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.19.feed_forward.output_dense.weight', 'mert_model.encoder.layers.19.feed_forward.output_dense.bias', 'mert_model.encoder.layers.19.final_layer_norm.weight', 'mert_model.encoder.layers.19.final_layer_norm.bias', 'mert_model.encoder.layers.20.attention.k_proj.weight', 'mert_model.encoder.layers.20.attention.k_proj.bias', 'mert_model.encoder.layers.20.attention.v_proj.weight', 'mert_model.encoder.layers.20.attention.v_proj.bias', 'mert_model.encoder.layers.20.attention.q_proj.weight', 'mert_model.encoder.layers.20.attention.q_proj.bias', 'mert_model.encoder.layers.20.attention.out_proj.weight', 'mert_model.encoder.layers.20.attention.out_proj.bias', 'mert_model.encoder.layers.20.layer_norm.weight', 'mert_model.encoder.layers.20.layer_norm.bias', 'mert_model.encoder.layers.20.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.20.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.20.feed_forward.output_dense.weight', 'mert_model.encoder.layers.20.feed_forward.output_dense.bias', 'mert_model.encoder.layers.20.final_layer_norm.weight', 'mert_model.encoder.layers.20.final_layer_norm.bias', 'mert_model.encoder.layers.21.attention.k_proj.weight', 'mert_model.encoder.layers.21.attention.k_proj.bias', 'mert_model.encoder.layers.21.attention.v_proj.weight', 'mert_model.encoder.layers.21.attention.v_proj.bias', 'mert_model.encoder.layers.21.attention.q_proj.weight', 'mert_model.encoder.layers.21.attention.q_proj.bias', 'mert_model.encoder.layers.21.attention.out_proj.weight', 'mert_model.encoder.layers.21.attention.out_proj.bias', 'mert_model.encoder.layers.21.layer_norm.weight', 'mert_model.encoder.layers.21.layer_norm.bias', 'mert_model.encoder.layers.21.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.21.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.21.feed_forward.output_dense.weight', 'mert_model.encoder.layers.21.feed_forward.output_dense.bias', 'mert_model.encoder.layers.21.final_layer_norm.weight', 'mert_model.encoder.layers.21.final_layer_norm.bias', 'mert_model.encoder.layers.22.attention.k_proj.weight', 'mert_model.encoder.layers.22.attention.k_proj.bias', 'mert_model.encoder.layers.22.attention.v_proj.weight', 'mert_model.encoder.layers.22.attention.v_proj.bias', 'mert_model.encoder.layers.22.attention.q_proj.weight', 'mert_model.encoder.layers.22.attention.q_proj.bias', 'mert_model.encoder.layers.22.attention.out_proj.weight', 'mert_model.encoder.layers.22.attention.out_proj.bias', 'mert_model.encoder.layers.22.layer_norm.weight', 'mert_model.encoder.layers.22.layer_norm.bias', 'mert_model.encoder.layers.22.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.22.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.22.feed_forward.output_dense.weight', 'mert_model.encoder.layers.22.feed_forward.output_dense.bias', 'mert_model.encoder.layers.22.final_layer_norm.weight', 'mert_model.encoder.layers.22.final_layer_norm.bias', 'mert_model.encoder.layers.23.attention.k_proj.weight', 'mert_model.encoder.layers.23.attention.k_proj.bias', 'mert_model.encoder.layers.23.attention.v_proj.weight', 'mert_model.encoder.layers.23.attention.v_proj.bias', 'mert_model.encoder.layers.23.attention.q_proj.weight', 'mert_model.encoder.layers.23.attention.q_proj.bias', 'mert_model.encoder.layers.23.attention.out_proj.weight', 'mert_model.encoder.layers.23.attention.out_proj.bias', 'mert_model.encoder.layers.23.layer_norm.weight', 'mert_model.encoder.layers.23.layer_norm.bias', 'mert_model.encoder.layers.23.feed_forward.intermediate_dense.weight', 'mert_model.encoder.layers.23.feed_forward.intermediate_dense.bias', 'mert_model.encoder.layers.23.feed_forward.output_dense.weight', 'mert_model.encoder.layers.23.feed_forward.output_dense.bias', 'mert_model.encoder.layers.23.final_layer_norm.weight', 'mert_model.encoder.layers.23.final_layer_norm.bias', 'hubert_model.masked_spec_embed', 'hubert_model.feature_extractor.conv_layers.0.conv.weight', 'hubert_model.feature_extractor.conv_layers.0.layer_norm.weight', 'hubert_model.feature_extractor.conv_layers.0.layer_norm.bias', 'hubert_model.feature_extractor.conv_layers.1.conv.weight', 'hubert_model.feature_extractor.conv_layers.2.conv.weight', 'hubert_model.feature_extractor.conv_layers.3.conv.weight', 'hubert_model.feature_extractor.conv_layers.4.conv.weight', 'hubert_model.feature_extractor.conv_layers.5.conv.weight', 'hubert_model.feature_extractor.conv_layers.6.conv.weight', 'hubert_model.feature_projection.layer_norm.weight', 'hubert_model.feature_projection.layer_norm.bias', 'hubert_model.feature_projection.projection.weight', 'hubert_model.feature_projection.projection.bias', 'hubert_model.encoder.pos_conv_embed.conv.bias', 'hubert_model.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert_model.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'hubert_model.encoder.layer_norm.weight', 'hubert_model.encoder.layer_norm.bias', 'hubert_model.encoder.layers.0.attention.k_proj.weight', 'hubert_model.encoder.layers.0.attention.k_proj.bias', 'hubert_model.encoder.layers.0.attention.v_proj.weight', 'hubert_model.encoder.layers.0.attention.v_proj.bias', 'hubert_model.encoder.layers.0.attention.q_proj.weight', 'hubert_model.encoder.layers.0.attention.q_proj.bias', 'hubert_model.encoder.layers.0.attention.out_proj.weight', 'hubert_model.encoder.layers.0.attention.out_proj.bias', 'hubert_model.encoder.layers.0.layer_norm.weight', 'hubert_model.encoder.layers.0.layer_norm.bias', 'hubert_model.encoder.layers.0.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.0.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.0.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.0.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.0.final_layer_norm.weight', 'hubert_model.encoder.layers.0.final_layer_norm.bias', 'hubert_model.encoder.layers.1.attention.k_proj.weight', 'hubert_model.encoder.layers.1.attention.k_proj.bias', 'hubert_model.encoder.layers.1.attention.v_proj.weight', 'hubert_model.encoder.layers.1.attention.v_proj.bias', 'hubert_model.encoder.layers.1.attention.q_proj.weight', 'hubert_model.encoder.layers.1.attention.q_proj.bias', 'hubert_model.encoder.layers.1.attention.out_proj.weight', 'hubert_model.encoder.layers.1.attention.out_proj.bias', 'hubert_model.encoder.layers.1.layer_norm.weight', 'hubert_model.encoder.layers.1.layer_norm.bias', 'hubert_model.encoder.layers.1.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.1.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.1.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.1.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.1.final_layer_norm.weight', 'hubert_model.encoder.layers.1.final_layer_norm.bias', 'hubert_model.encoder.layers.2.attention.k_proj.weight', 'hubert_model.encoder.layers.2.attention.k_proj.bias', 'hubert_model.encoder.layers.2.attention.v_proj.weight', 'hubert_model.encoder.layers.2.attention.v_proj.bias', 'hubert_model.encoder.layers.2.attention.q_proj.weight', 'hubert_model.encoder.layers.2.attention.q_proj.bias', 'hubert_model.encoder.layers.2.attention.out_proj.weight', 'hubert_model.encoder.layers.2.attention.out_proj.bias', 'hubert_model.encoder.layers.2.layer_norm.weight', 'hubert_model.encoder.layers.2.layer_norm.bias', 'hubert_model.encoder.layers.2.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.2.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.2.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.2.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.2.final_layer_norm.weight', 'hubert_model.encoder.layers.2.final_layer_norm.bias', 'hubert_model.encoder.layers.3.attention.k_proj.weight', 'hubert_model.encoder.layers.3.attention.k_proj.bias', 'hubert_model.encoder.layers.3.attention.v_proj.weight', 'hubert_model.encoder.layers.3.attention.v_proj.bias', 'hubert_model.encoder.layers.3.attention.q_proj.weight', 'hubert_model.encoder.layers.3.attention.q_proj.bias', 'hubert_model.encoder.layers.3.attention.out_proj.weight', 'hubert_model.encoder.layers.3.attention.out_proj.bias', 'hubert_model.encoder.layers.3.layer_norm.weight', 'hubert_model.encoder.layers.3.layer_norm.bias', 'hubert_model.encoder.layers.3.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.3.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.3.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.3.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.3.final_layer_norm.weight', 'hubert_model.encoder.layers.3.final_layer_norm.bias', 'hubert_model.encoder.layers.4.attention.k_proj.weight', 'hubert_model.encoder.layers.4.attention.k_proj.bias', 'hubert_model.encoder.layers.4.attention.v_proj.weight', 'hubert_model.encoder.layers.4.attention.v_proj.bias', 'hubert_model.encoder.layers.4.attention.q_proj.weight', 'hubert_model.encoder.layers.4.attention.q_proj.bias', 'hubert_model.encoder.layers.4.attention.out_proj.weight', 'hubert_model.encoder.layers.4.attention.out_proj.bias', 'hubert_model.encoder.layers.4.layer_norm.weight', 'hubert_model.encoder.layers.4.layer_norm.bias', 'hubert_model.encoder.layers.4.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.4.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.4.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.4.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.4.final_layer_norm.weight', 'hubert_model.encoder.layers.4.final_layer_norm.bias', 'hubert_model.encoder.layers.5.attention.k_proj.weight', 'hubert_model.encoder.layers.5.attention.k_proj.bias', 'hubert_model.encoder.layers.5.attention.v_proj.weight', 'hubert_model.encoder.layers.5.attention.v_proj.bias', 'hubert_model.encoder.layers.5.attention.q_proj.weight', 'hubert_model.encoder.layers.5.attention.q_proj.bias', 'hubert_model.encoder.layers.5.attention.out_proj.weight', 'hubert_model.encoder.layers.5.attention.out_proj.bias', 'hubert_model.encoder.layers.5.layer_norm.weight', 'hubert_model.encoder.layers.5.layer_norm.bias', 'hubert_model.encoder.layers.5.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.5.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.5.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.5.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.5.final_layer_norm.weight', 'hubert_model.encoder.layers.5.final_layer_norm.bias', 'hubert_model.encoder.layers.6.attention.k_proj.weight', 'hubert_model.encoder.layers.6.attention.k_proj.bias', 'hubert_model.encoder.layers.6.attention.v_proj.weight', 'hubert_model.encoder.layers.6.attention.v_proj.bias', 'hubert_model.encoder.layers.6.attention.q_proj.weight', 'hubert_model.encoder.layers.6.attention.q_proj.bias', 'hubert_model.encoder.layers.6.attention.out_proj.weight', 'hubert_model.encoder.layers.6.attention.out_proj.bias', 'hubert_model.encoder.layers.6.layer_norm.weight', 'hubert_model.encoder.layers.6.layer_norm.bias', 'hubert_model.encoder.layers.6.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.6.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.6.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.6.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.6.final_layer_norm.weight', 'hubert_model.encoder.layers.6.final_layer_norm.bias', 'hubert_model.encoder.layers.7.attention.k_proj.weight', 'hubert_model.encoder.layers.7.attention.k_proj.bias', 'hubert_model.encoder.layers.7.attention.v_proj.weight', 'hubert_model.encoder.layers.7.attention.v_proj.bias', 'hubert_model.encoder.layers.7.attention.q_proj.weight', 'hubert_model.encoder.layers.7.attention.q_proj.bias', 'hubert_model.encoder.layers.7.attention.out_proj.weight', 'hubert_model.encoder.layers.7.attention.out_proj.bias', 'hubert_model.encoder.layers.7.layer_norm.weight', 'hubert_model.encoder.layers.7.layer_norm.bias', 'hubert_model.encoder.layers.7.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.7.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.7.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.7.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.7.final_layer_norm.weight', 'hubert_model.encoder.layers.7.final_layer_norm.bias', 'hubert_model.encoder.layers.8.attention.k_proj.weight', 'hubert_model.encoder.layers.8.attention.k_proj.bias', 'hubert_model.encoder.layers.8.attention.v_proj.weight', 'hubert_model.encoder.layers.8.attention.v_proj.bias', 'hubert_model.encoder.layers.8.attention.q_proj.weight', 'hubert_model.encoder.layers.8.attention.q_proj.bias', 'hubert_model.encoder.layers.8.attention.out_proj.weight', 'hubert_model.encoder.layers.8.attention.out_proj.bias', 'hubert_model.encoder.layers.8.layer_norm.weight', 'hubert_model.encoder.layers.8.layer_norm.bias', 'hubert_model.encoder.layers.8.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.8.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.8.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.8.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.8.final_layer_norm.weight', 'hubert_model.encoder.layers.8.final_layer_norm.bias', 'hubert_model.encoder.layers.9.attention.k_proj.weight', 'hubert_model.encoder.layers.9.attention.k_proj.bias', 'hubert_model.encoder.layers.9.attention.v_proj.weight', 'hubert_model.encoder.layers.9.attention.v_proj.bias', 'hubert_model.encoder.layers.9.attention.q_proj.weight', 'hubert_model.encoder.layers.9.attention.q_proj.bias', 'hubert_model.encoder.layers.9.attention.out_proj.weight', 'hubert_model.encoder.layers.9.attention.out_proj.bias', 'hubert_model.encoder.layers.9.layer_norm.weight', 'hubert_model.encoder.layers.9.layer_norm.bias', 'hubert_model.encoder.layers.9.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.9.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.9.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.9.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.9.final_layer_norm.weight', 'hubert_model.encoder.layers.9.final_layer_norm.bias', 'hubert_model.encoder.layers.10.attention.k_proj.weight', 'hubert_model.encoder.layers.10.attention.k_proj.bias', 'hubert_model.encoder.layers.10.attention.v_proj.weight', 'hubert_model.encoder.layers.10.attention.v_proj.bias', 'hubert_model.encoder.layers.10.attention.q_proj.weight', 'hubert_model.encoder.layers.10.attention.q_proj.bias', 'hubert_model.encoder.layers.10.attention.out_proj.weight', 'hubert_model.encoder.layers.10.attention.out_proj.bias', 'hubert_model.encoder.layers.10.layer_norm.weight', 'hubert_model.encoder.layers.10.layer_norm.bias', 'hubert_model.encoder.layers.10.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.10.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.10.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.10.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.10.final_layer_norm.weight', 'hubert_model.encoder.layers.10.final_layer_norm.bias', 'hubert_model.encoder.layers.11.attention.k_proj.weight', 'hubert_model.encoder.layers.11.attention.k_proj.bias', 'hubert_model.encoder.layers.11.attention.v_proj.weight', 'hubert_model.encoder.layers.11.attention.v_proj.bias', 'hubert_model.encoder.layers.11.attention.q_proj.weight', 'hubert_model.encoder.layers.11.attention.q_proj.bias', 'hubert_model.encoder.layers.11.attention.out_proj.weight', 'hubert_model.encoder.layers.11.attention.out_proj.bias', 'hubert_model.encoder.layers.11.layer_norm.weight', 'hubert_model.encoder.layers.11.layer_norm.bias', 'hubert_model.encoder.layers.11.feed_forward.intermediate_dense.weight', 'hubert_model.encoder.layers.11.feed_forward.intermediate_dense.bias', 'hubert_model.encoder.layers.11.feed_forward.output_dense.weight', 'hubert_model.encoder.layers.11.feed_forward.output_dense.bias', 'hubert_model.encoder.layers.11.final_layer_norm.weight', 'hubert_model.encoder.layers.11.final_layer_norm.bias', 'vae.encoder.conv_in.weight', 'vae.encoder.conv_in.bias', 'vae.encoder.down_blocks.0.0.conv1.weight', 'vae.encoder.down_blocks.0.0.conv1.bias', 'vae.encoder.down_blocks.0.0.conv2.weight', 'vae.encoder.down_blocks.0.0.norm.weight', 'vae.encoder.down_blocks.0.0.norm.bias', 'vae.encoder.down_blocks.0.1.conv1.weight', 'vae.encoder.down_blocks.0.1.conv1.bias', 'vae.encoder.down_blocks.0.1.conv2.weight', 'vae.encoder.down_blocks.0.1.norm.weight', 'vae.encoder.down_blocks.0.1.norm.bias', 'vae.encoder.down_blocks.0.2.conv.weight', 'vae.encoder.down_blocks.0.2.conv.bias', 'vae.encoder.down_blocks.1.0.conv1.weight', 'vae.encoder.down_blocks.1.0.conv1.bias', 'vae.encoder.down_blocks.1.0.conv2.weight', 'vae.encoder.down_blocks.1.0.norm.weight', 'vae.encoder.down_blocks.1.0.norm.bias', 'vae.encoder.down_blocks.1.1.conv1.weight', 'vae.encoder.down_blocks.1.1.conv1.bias', 'vae.encoder.down_blocks.1.1.conv2.weight', 'vae.encoder.down_blocks.1.1.norm.weight', 'vae.encoder.down_blocks.1.1.norm.bias', 'vae.encoder.down_blocks.1.2.conv.weight', 'vae.encoder.down_blocks.1.2.conv.bias', 'vae.encoder.down_blocks.2.0.conv1.weight', 'vae.encoder.down_blocks.2.0.conv1.bias', 'vae.encoder.down_blocks.2.0.conv2.weight', 'vae.encoder.down_blocks.2.0.norm.weight', 'vae.encoder.down_blocks.2.0.norm.bias', 'vae.encoder.down_blocks.2.1.conv1.weight', 'vae.encoder.down_blocks.2.1.conv1.bias', 'vae.encoder.down_blocks.2.1.conv2.weight', 'vae.encoder.down_blocks.2.1.norm.weight', 'vae.encoder.down_blocks.2.1.norm.bias', 'vae.encoder.down_blocks.2.2.conv1.weight', 'vae.encoder.down_blocks.2.2.conv1.bias', 'vae.encoder.down_blocks.2.2.conv2.weight', 'vae.encoder.down_blocks.2.2.norm.weight', 'vae.encoder.down_blocks.2.2.norm.bias', 'vae.encoder.down_blocks.2.3.conv.weight', 'vae.encoder.down_blocks.2.3.conv.bias', 'vae.encoder.down_blocks.3.0.attn.to_q.weight', 'vae.encoder.down_blocks.3.0.attn.to_k.weight', 'vae.encoder.down_blocks.3.0.attn.to_v.weight', 'vae.encoder.down_blocks.3.0.attn.to_qkv_multiscale.0.proj_in.weight', 'vae.encoder.down_blocks.3.0.attn.to_qkv_multiscale.0.proj_out.weight', 'vae.encoder.down_blocks.3.0.attn.to_out.weight', 'vae.encoder.down_blocks.3.0.attn.norm_out.weight', 'vae.encoder.down_blocks.3.0.attn.norm_out.bias', 'vae.encoder.down_blocks.3.0.conv_out.conv_inverted.weight', 'vae.encoder.down_blocks.3.0.conv_out.conv_inverted.bias', 'vae.encoder.down_blocks.3.0.conv_out.conv_depth.weight', 'vae.encoder.down_blocks.3.0.conv_out.conv_depth.bias', 'vae.encoder.down_blocks.3.0.conv_out.conv_point.weight', 'vae.encoder.down_blocks.3.0.conv_out.norm.weight', 'vae.encoder.down_blocks.3.0.conv_out.norm.bias', 'vae.encoder.down_blocks.3.1.attn.to_q.weight', 'vae.encoder.down_blocks.3.1.attn.to_k.weight', 'vae.encoder.down_blocks.3.1.attn.to_v.weight', 'vae.encoder.down_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight', 'vae.encoder.down_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight', 'vae.encoder.down_blocks.3.1.attn.to_out.weight', 'vae.encoder.down_blocks.3.1.attn.norm_out.weight', 'vae.encoder.down_blocks.3.1.attn.norm_out.bias', 'vae.encoder.down_blocks.3.1.conv_out.conv_inverted.weight', 'vae.encoder.down_blocks.3.1.conv_out.conv_inverted.bias', 'vae.encoder.down_blocks.3.1.conv_out.conv_depth.weight', 'vae.encoder.down_blocks.3.1.conv_out.conv_depth.bias', 'vae.encoder.down_blocks.3.1.conv_out.conv_point.weight', 'vae.encoder.down_blocks.3.1.conv_out.norm.weight', 'vae.encoder.down_blocks.3.1.conv_out.norm.bias', 'vae.encoder.down_blocks.3.2.attn.to_q.weight', 'vae.encoder.down_blocks.3.2.attn.to_k.weight', 'vae.encoder.down_blocks.3.2.attn.to_v.weight', 'vae.encoder.down_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight', 'vae.encoder.down_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight', 'vae.encoder.down_blocks.3.2.attn.to_out.weight', 'vae.encoder.down_blocks.3.2.attn.norm_out.weight', 'vae.encoder.down_blocks.3.2.attn.norm_out.bias', 'vae.encoder.down_blocks.3.2.conv_out.conv_inverted.weight', 'vae.encoder.down_blocks.3.2.conv_out.conv_inverted.bias', 'vae.encoder.down_blocks.3.2.conv_out.conv_depth.weight', 'vae.encoder.down_blocks.3.2.conv_out.conv_depth.bias', 'vae.encoder.down_blocks.3.2.conv_out.conv_point.weight', 'vae.encoder.down_blocks.3.2.conv_out.norm.weight', 'vae.encoder.down_blocks.3.2.conv_out.norm.bias', 'vae.encoder.conv_out.weight', 'vae.encoder.conv_out.bias', 'vae.decoder.conv_in.weight', 'vae.decoder.conv_in.bias', 'vae.decoder.up_blocks.0.0.conv.weight', 'vae.decoder.up_blocks.0.0.conv.bias', 'vae.decoder.up_blocks.0.1.conv1.weight', 'vae.decoder.up_blocks.0.1.conv1.bias', 'vae.decoder.up_blocks.0.1.conv2.weight', 'vae.decoder.up_blocks.0.1.norm.weight', 'vae.decoder.up_blocks.0.1.norm.bias', 'vae.decoder.up_blocks.0.2.conv1.weight', 'vae.decoder.up_blocks.0.2.conv1.bias', 'vae.decoder.up_blocks.0.2.conv2.weight', 'vae.decoder.up_blocks.0.2.norm.weight', 'vae.decoder.up_blocks.0.2.norm.bias', 'vae.decoder.up_blocks.0.3.conv1.weight', 'vae.decoder.up_blocks.0.3.conv1.bias', 'vae.decoder.up_blocks.0.3.conv2.weight', 'vae.decoder.up_blocks.0.3.norm.weight', 'vae.decoder.up_blocks.0.3.norm.bias', 'vae.decoder.up_blocks.1.0.conv.weight', 'vae.decoder.up_blocks.1.0.conv.bias', 'vae.decoder.up_blocks.1.1.conv1.weight', 'vae.decoder.up_blocks.1.1.conv1.bias', 'vae.decoder.up_blocks.1.1.conv2.weight', 'vae.decoder.up_blocks.1.1.norm.weight', 'vae.decoder.up_blocks.1.1.norm.bias', 'vae.decoder.up_blocks.1.2.conv1.weight', 'vae.decoder.up_blocks.1.2.conv1.bias', 'vae.decoder.up_blocks.1.2.conv2.weight', 'vae.decoder.up_blocks.1.2.norm.weight', 'vae.decoder.up_blocks.1.2.norm.bias', 'vae.decoder.up_blocks.1.3.conv1.weight', 'vae.decoder.up_blocks.1.3.conv1.bias', 'vae.decoder.up_blocks.1.3.conv2.weight', 'vae.decoder.up_blocks.1.3.norm.weight', 'vae.decoder.up_blocks.1.3.norm.bias', 'vae.decoder.up_blocks.2.0.conv.weight', 'vae.decoder.up_blocks.2.0.conv.bias', 'vae.decoder.up_blocks.2.1.conv1.weight', 'vae.decoder.up_blocks.2.1.conv1.bias', 'vae.decoder.up_blocks.2.1.conv2.weight', 'vae.decoder.up_blocks.2.1.norm.weight', 'vae.decoder.up_blocks.2.1.norm.bias', 'vae.decoder.up_blocks.2.2.conv1.weight', 'vae.decoder.up_blocks.2.2.conv1.bias', 'vae.decoder.up_blocks.2.2.conv2.weight', 'vae.decoder.up_blocks.2.2.norm.weight', 'vae.decoder.up_blocks.2.2.norm.bias', 'vae.decoder.up_blocks.2.3.conv1.weight', 'vae.decoder.up_blocks.2.3.conv1.bias', 'vae.decoder.up_blocks.2.3.conv2.weight', 'vae.decoder.up_blocks.2.3.norm.weight', 'vae.decoder.up_blocks.2.3.norm.bias', 'vae.decoder.up_blocks.3.0.attn.to_q.weight', 'vae.decoder.up_blocks.3.0.attn.to_k.weight', 'vae.decoder.up_blocks.3.0.attn.to_v.weight', 'vae.decoder.up_blocks.3.0.attn.to_qkv_multiscale.0.proj_in.weight', 'vae.decoder.up_blocks.3.0.attn.to_qkv_multiscale.0.proj_out.weight', 'vae.decoder.up_blocks.3.0.attn.to_out.weight', 'vae.decoder.up_blocks.3.0.attn.norm_out.weight', 'vae.decoder.up_blocks.3.0.attn.norm_out.bias', 'vae.decoder.up_blocks.3.0.conv_out.conv_inverted.weight', 'vae.decoder.up_blocks.3.0.conv_out.conv_inverted.bias', 'vae.decoder.up_blocks.3.0.conv_out.conv_depth.weight', 'vae.decoder.up_blocks.3.0.conv_out.conv_depth.bias', 'vae.decoder.up_blocks.3.0.conv_out.conv_point.weight', 'vae.decoder.up_blocks.3.0.conv_out.norm.weight', 'vae.decoder.up_blocks.3.0.conv_out.norm.bias', 'vae.decoder.up_blocks.3.1.attn.to_q.weight', 'vae.decoder.up_blocks.3.1.attn.to_k.weight', 'vae.decoder.up_blocks.3.1.attn.to_v.weight', 'vae.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight', 'vae.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight', 'vae.decoder.up_blocks.3.1.attn.to_out.weight', 'vae.decoder.up_blocks.3.1.attn.norm_out.weight', 'vae.decoder.up_blocks.3.1.attn.norm_out.bias', 'vae.decoder.up_blocks.3.1.conv_out.conv_inverted.weight', 'vae.decoder.up_blocks.3.1.conv_out.conv_inverted.bias', 'vae.decoder.up_blocks.3.1.conv_out.conv_depth.weight', 'vae.decoder.up_blocks.3.1.conv_out.conv_depth.bias', 'vae.decoder.up_blocks.3.1.conv_out.conv_point.weight', 'vae.decoder.up_blocks.3.1.conv_out.norm.weight', 'vae.decoder.up_blocks.3.1.conv_out.norm.bias', 'vae.decoder.up_blocks.3.2.attn.to_q.weight', 'vae.decoder.up_blocks.3.2.attn.to_k.weight', 'vae.decoder.up_blocks.3.2.attn.to_v.weight', 'vae.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight', 'vae.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight', 'vae.decoder.up_blocks.3.2.attn.to_out.weight', 'vae.decoder.up_blocks.3.2.attn.norm_out.weight', 'vae.decoder.up_blocks.3.2.attn.norm_out.bias', 'vae.decoder.up_blocks.3.2.conv_out.conv_inverted.weight', 'vae.decoder.up_blocks.3.2.conv_out.conv_inverted.bias', 'vae.decoder.up_blocks.3.2.conv_out.conv_depth.weight', 'vae.decoder.up_blocks.3.2.conv_out.conv_depth.bias', 'vae.decoder.up_blocks.3.2.conv_out.conv_point.weight', 'vae.decoder.up_blocks.3.2.conv_out.norm.weight', 'vae.decoder.up_blocks.3.2.conv_out.norm.bias', 'vae.decoder.norm_out.weight', 'vae.decoder.norm_out.bias', 'vae.decoder.conv_out.weight', 'vae.decoder.conv_out.bias', 'vae.vocoder.backbone.channel_layers.0.0.weight', 'vae.vocoder.backbone.channel_layers.0.0.bias', 'vae.vocoder.backbone.channel_layers.0.1.weight', 'vae.vocoder.backbone.channel_layers.0.1.bias', 'vae.vocoder.backbone.channel_layers.1.0.weight', 'vae.vocoder.backbone.channel_layers.1.0.bias', 'vae.vocoder.backbone.channel_layers.1.1.weight', 'vae.vocoder.backbone.channel_layers.1.1.bias', 'vae.vocoder.backbone.channel_layers.2.0.weight', 'vae.vocoder.backbone.channel_layers.2.0.bias', 'vae.vocoder.backbone.channel_layers.2.1.weight', 'vae.vocoder.backbone.channel_layers.2.1.bias', 'vae.vocoder.backbone.channel_layers.3.0.weight', 'vae.vocoder.backbone.channel_layers.3.0.bias', 'vae.vocoder.backbone.channel_layers.3.1.weight', 'vae.vocoder.backbone.channel_layers.3.1.bias', 'vae.vocoder.backbone.stages.0.0.gamma', 'vae.vocoder.backbone.stages.0.0.dwconv.weight', 'vae.vocoder.backbone.stages.0.0.dwconv.bias', 'vae.vocoder.backbone.stages.0.0.norm.weight', 'vae.vocoder.backbone.stages.0.0.norm.bias', 'vae.vocoder.backbone.stages.0.0.pwconv1.weight', 'vae.vocoder.backbone.stages.0.0.pwconv1.bias', 'vae.vocoder.backbone.stages.0.0.pwconv2.weight', 'vae.vocoder.backbone.stages.0.0.pwconv2.bias', 'vae.vocoder.backbone.stages.0.1.gamma', 'vae.vocoder.backbone.stages.0.1.dwconv.weight', 'vae.vocoder.backbone.stages.0.1.dwconv.bias', 'vae.vocoder.backbone.stages.0.1.norm.weight', 'vae.vocoder.backbone.stages.0.1.norm.bias', 'vae.vocoder.backbone.stages.0.1.pwconv1.weight', 'vae.vocoder.backbone.stages.0.1.pwconv1.bias', 'vae.vocoder.backbone.stages.0.1.pwconv2.weight', 'vae.vocoder.backbone.stages.0.1.pwconv2.bias', 'vae.vocoder.backbone.stages.0.2.gamma', 'vae.vocoder.backbone.stages.0.2.dwconv.weight', 'vae.vocoder.backbone.stages.0.2.dwconv.bias', 'vae.vocoder.backbone.stages.0.2.norm.weight', 'vae.vocoder.backbone.stages.0.2.norm.bias', 'vae.vocoder.backbone.stages.0.2.pwconv1.weight', 'vae.vocoder.backbone.stages.0.2.pwconv1.bias', 'vae.vocoder.backbone.stages.0.2.pwconv2.weight', 'vae.vocoder.backbone.stages.0.2.pwconv2.bias', 'vae.vocoder.backbone.stages.1.0.gamma', 'vae.vocoder.backbone.stages.1.0.dwconv.weight', 'vae.vocoder.backbone.stages.1.0.dwconv.bias', 'vae.vocoder.backbone.stages.1.0.norm.weight', 'vae.vocoder.backbone.stages.1.0.norm.bias', 'vae.vocoder.backbone.stages.1.0.pwconv1.weight', 'vae.vocoder.backbone.stages.1.0.pwconv1.bias', 'vae.vocoder.backbone.stages.1.0.pwconv2.weight', 'vae.vocoder.backbone.stages.1.0.pwconv2.bias', 'vae.vocoder.backbone.stages.1.1.gamma', 'vae.vocoder.backbone.stages.1.1.dwconv.weight', 'vae.vocoder.backbone.stages.1.1.dwconv.bias', 'vae.vocoder.backbone.stages.1.1.norm.weight', 'vae.vocoder.backbone.stages.1.1.norm.bias', 'vae.vocoder.backbone.stages.1.1.pwconv1.weight', 'vae.vocoder.backbone.stages.1.1.pwconv1.bias', 'vae.vocoder.backbone.stages.1.1.pwconv2.weight', 'vae.vocoder.backbone.stages.1.1.pwconv2.bias', 'vae.vocoder.backbone.stages.1.2.gamma', 'vae.vocoder.backbone.stages.1.2.dwconv.weight', 'vae.vocoder.backbone.stages.1.2.dwconv.bias', 'vae.vocoder.backbone.stages.1.2.norm.weight', 'vae.vocoder.backbone.stages.1.2.norm.bias', 'vae.vocoder.backbone.stages.1.2.pwconv1.weight', 'vae.vocoder.backbone.stages.1.2.pwconv1.bias', 'vae.vocoder.backbone.stages.1.2.pwconv2.weight', 'vae.vocoder.backbone.stages.1.2.pwconv2.bias', 'vae.vocoder.backbone.stages.2.0.gamma', 'vae.vocoder.backbone.stages.2.0.dwconv.weight', 'vae.vocoder.backbone.stages.2.0.dwconv.bias', 'vae.vocoder.backbone.stages.2.0.norm.weight', 'vae.vocoder.backbone.stages.2.0.norm.bias', 'vae.vocoder.backbone.stages.2.0.pwconv1.weight', 'vae.vocoder.backbone.stages.2.0.pwconv1.bias', 'vae.vocoder.backbone.stages.2.0.pwconv2.weight', 'vae.vocoder.backbone.stages.2.0.pwconv2.bias', 'vae.vocoder.backbone.stages.2.1.gamma', 'vae.vocoder.backbone.stages.2.1.dwconv.weight', 'vae.vocoder.backbone.stages.2.1.dwconv.bias', 'vae.vocoder.backbone.stages.2.1.norm.weight', 'vae.vocoder.backbone.stages.2.1.norm.bias', 'vae.vocoder.backbone.stages.2.1.pwconv1.weight', 'vae.vocoder.backbone.stages.2.1.pwconv1.bias', 'vae.vocoder.backbone.stages.2.1.pwconv2.weight', 'vae.vocoder.backbone.stages.2.1.pwconv2.bias', 'vae.vocoder.backbone.stages.2.2.gamma', 'vae.vocoder.backbone.stages.2.2.dwconv.weight', 'vae.vocoder.backbone.stages.2.2.dwconv.bias', 'vae.vocoder.backbone.stages.2.2.norm.weight', 'vae.vocoder.backbone.stages.2.2.norm.bias', 'vae.vocoder.backbone.stages.2.2.pwconv1.weight', 'vae.vocoder.backbone.stages.2.2.pwconv1.bias', 'vae.vocoder.backbone.stages.2.2.pwconv2.weight', 'vae.vocoder.backbone.stages.2.2.pwconv2.bias', 'vae.vocoder.backbone.stages.2.3.gamma', 'vae.vocoder.backbone.stages.2.3.dwconv.weight', 'vae.vocoder.backbone.stages.2.3.dwconv.bias', 'vae.vocoder.backbone.stages.2.3.norm.weight', 'vae.vocoder.backbone.stages.2.3.norm.bias', 'vae.vocoder.backbone.stages.2.3.pwconv1.weight', 'vae.vocoder.backbone.stages.2.3.pwconv1.bias', 'vae.vocoder.backbone.stages.2.3.pwconv2.weight', 'vae.vocoder.backbone.stages.2.3.pwconv2.bias', 'vae.vocoder.backbone.stages.2.4.gamma', 'vae.vocoder.backbone.stages.2.4.dwconv.weight', 'vae.vocoder.backbone.stages.2.4.dwconv.bias', 'vae.vocoder.backbone.stages.2.4.norm.weight', 'vae.vocoder.backbone.stages.2.4.norm.bias', 'vae.vocoder.backbone.stages.2.4.pwconv1.weight', 'vae.vocoder.backbone.stages.2.4.pwconv1.bias', 'vae.vocoder.backbone.stages.2.4.pwconv2.weight', 'vae.vocoder.backbone.stages.2.4.pwconv2.bias', 'vae.vocoder.backbone.stages.2.5.gamma', 'vae.vocoder.backbone.stages.2.5.dwconv.weight', 'vae.vocoder.backbone.stages.2.5.dwconv.bias', 'vae.vocoder.backbone.stages.2.5.norm.weight', 'vae.vocoder.backbone.stages.2.5.norm.bias', 'vae.vocoder.backbone.stages.2.5.pwconv1.weight', 'vae.vocoder.backbone.stages.2.5.pwconv1.bias', 'vae.vocoder.backbone.stages.2.5.pwconv2.weight', 'vae.vocoder.backbone.stages.2.5.pwconv2.bias', 'vae.vocoder.backbone.stages.2.6.gamma', 'vae.vocoder.backbone.stages.2.6.dwconv.weight', 'vae.vocoder.backbone.stages.2.6.dwconv.bias', 'vae.vocoder.backbone.stages.2.6.norm.weight', 'vae.vocoder.backbone.stages.2.6.norm.bias', 'vae.vocoder.backbone.stages.2.6.pwconv1.weight', 'vae.vocoder.backbone.stages.2.6.pwconv1.bias', 'vae.vocoder.backbone.stages.2.6.pwconv2.weight', 'vae.vocoder.backbone.stages.2.6.pwconv2.bias', 'vae.vocoder.backbone.stages.2.7.gamma', 'vae.vocoder.backbone.stages.2.7.dwconv.weight', 'vae.vocoder.backbone.stages.2.7.dwconv.bias', 'vae.vocoder.backbone.stages.2.7.norm.weight', 'vae.vocoder.backbone.stages.2.7.norm.bias', 'vae.vocoder.backbone.stages.2.7.pwconv1.weight', 'vae.vocoder.backbone.stages.2.7.pwconv1.bias', 'vae.vocoder.backbone.stages.2.7.pwconv2.weight', 'vae.vocoder.backbone.stages.2.7.pwconv2.bias', 'vae.vocoder.backbone.stages.2.8.gamma', 'vae.vocoder.backbone.stages.2.8.dwconv.weight', 'vae.vocoder.backbone.stages.2.8.dwconv.bias', 'vae.vocoder.backbone.stages.2.8.norm.weight', 'vae.vocoder.backbone.stages.2.8.norm.bias', 'vae.vocoder.backbone.stages.2.8.pwconv1.weight', 'vae.vocoder.backbone.stages.2.8.pwconv1.bias', 'vae.vocoder.backbone.stages.2.8.pwconv2.weight', 'vae.vocoder.backbone.stages.2.8.pwconv2.bias', 'vae.vocoder.backbone.stages.3.0.gamma', 'vae.vocoder.backbone.stages.3.0.dwconv.weight', 'vae.vocoder.backbone.stages.3.0.dwconv.bias', 'vae.vocoder.backbone.stages.3.0.norm.weight', 'vae.vocoder.backbone.stages.3.0.norm.bias', 'vae.vocoder.backbone.stages.3.0.pwconv1.weight', 'vae.vocoder.backbone.stages.3.0.pwconv1.bias', 'vae.vocoder.backbone.stages.3.0.pwconv2.weight', 'vae.vocoder.backbone.stages.3.0.pwconv2.bias', 'vae.vocoder.backbone.stages.3.1.gamma', 'vae.vocoder.backbone.stages.3.1.dwconv.weight', 'vae.vocoder.backbone.stages.3.1.dwconv.bias', 'vae.vocoder.backbone.stages.3.1.norm.weight', 'vae.vocoder.backbone.stages.3.1.norm.bias', 'vae.vocoder.backbone.stages.3.1.pwconv1.weight', 'vae.vocoder.backbone.stages.3.1.pwconv1.bias', 'vae.vocoder.backbone.stages.3.1.pwconv2.weight', 'vae.vocoder.backbone.stages.3.1.pwconv2.bias', 'vae.vocoder.backbone.stages.3.2.gamma', 'vae.vocoder.backbone.stages.3.2.dwconv.weight', 'vae.vocoder.backbone.stages.3.2.dwconv.bias', 'vae.vocoder.backbone.stages.3.2.norm.weight', 'vae.vocoder.backbone.stages.3.2.norm.bias', 'vae.vocoder.backbone.stages.3.2.pwconv1.weight', 'vae.vocoder.backbone.stages.3.2.pwconv1.bias', 'vae.vocoder.backbone.stages.3.2.pwconv2.weight', 'vae.vocoder.backbone.stages.3.2.pwconv2.bias', 'vae.vocoder.backbone.norm.weight', 'vae.vocoder.backbone.norm.bias', 'vae.vocoder.head.conv_pre.bias', 'vae.vocoder.head.conv_pre.weight_g', 'vae.vocoder.head.conv_pre.weight_v', 'vae.vocoder.head.ups.0.bias', 'vae.vocoder.head.ups.0.weight_g', 'vae.vocoder.head.ups.0.weight_v', 'vae.vocoder.head.ups.1.bias', 'vae.vocoder.head.ups.1.weight_g', 'vae.vocoder.head.ups.1.weight_v', 'vae.vocoder.head.ups.2.bias', 'vae.vocoder.head.ups.2.weight_g', 'vae.vocoder.head.ups.2.weight_v', 'vae.vocoder.head.ups.3.bias', 'vae.vocoder.head.ups.3.weight_g', 'vae.vocoder.head.ups.3.weight_v', 'vae.vocoder.head.ups.4.bias', 'vae.vocoder.head.ups.4.weight_g', 'vae.vocoder.head.ups.4.weight_v', 'vae.vocoder.head.ups.5.bias', 'vae.vocoder.head.ups.5.weight_g', 'vae.vocoder.head.ups.5.weight_v', 'vae.vocoder.head.ups.6.bias', 'vae.vocoder.head.ups.6.weight_g', 'vae.vocoder.head.ups.6.weight_v', 'vae.vocoder.head.resblocks.0.convs1.0.bias', 'vae.vocoder.head.resblocks.0.convs1.0.weight_g', 'vae.vocoder.head.resblocks.0.convs1.0.weight_v', 'vae.vocoder.head.resblocks.0.convs1.1.bias', 'vae.vocoder.head.resblocks.0.convs1.1.weight_g', 'vae.vocoder.head.resblocks.0.convs1.1.weight_v', 'vae.vocoder.head.resblocks.0.convs1.2.bias', 'vae.vocoder.head.resblocks.0.convs1.2.weight_g', 'vae.vocoder.head.resblocks.0.convs1.2.weight_v', 'vae.vocoder.head.resblocks.0.convs2.0.bias', 'vae.vocoder.head.resblocks.0.convs2.0.weight_g', 'vae.vocoder.head.resblocks.0.convs2.0.weight_v', 'vae.vocoder.head.resblocks.0.convs2.1.bias', 'vae.vocoder.head.resblocks.0.convs2.1.weight_g', 'vae.vocoder.head.resblocks.0.convs2.1.weight_v', 'vae.vocoder.head.resblocks.0.convs2.2.bias', 'vae.vocoder.head.resblocks.0.convs2.2.weight_g', 'vae.vocoder.head.resblocks.0.convs2.2.weight_v', 'vae.vocoder.head.resblocks.1.convs1.0.bias', 'vae.vocoder.head.resblocks.1.convs1.0.weight_g', 'vae.vocoder.head.resblocks.1.convs1.0.weight_v', 'vae.vocoder.head.resblocks.1.convs1.1.bias', 'vae.vocoder.head.resblocks.1.convs1.1.weight_g', 'vae.vocoder.head.resblocks.1.convs1.1.weight_v', 'vae.vocoder.head.resblocks.1.convs1.2.bias', 'vae.vocoder.head.resblocks.1.convs1.2.weight_g', 'vae.vocoder.head.resblocks.1.convs1.2.weight_v', 'vae.vocoder.head.resblocks.1.convs2.0.bias', 'vae.vocoder.head.resblocks.1.convs2.0.weight_g', 'vae.vocoder.head.resblocks.1.convs2.0.weight_v', 'vae.vocoder.head.resblocks.1.convs2.1.bias', 'vae.vocoder.head.resblocks.1.convs2.1.weight_g', 'vae.vocoder.head.resblocks.1.convs2.1.weight_v', 'vae.vocoder.head.resblocks.1.convs2.2.bias', 'vae.vocoder.head.resblocks.1.convs2.2.weight_g', 'vae.vocoder.head.resblocks.1.convs2.2.weight_v', 'vae.vocoder.head.resblocks.2.convs1.0.bias', 'vae.vocoder.head.resblocks.2.convs1.0.weight_g', 'vae.vocoder.head.resblocks.2.convs1.0.weight_v', 'vae.vocoder.head.resblocks.2.convs1.1.bias', 'vae.vocoder.head.resblocks.2.convs1.1.weight_g', 'vae.vocoder.head.resblocks.2.convs1.1.weight_v', 'vae.vocoder.head.resblocks.2.convs1.2.bias', 'vae.vocoder.head.resblocks.2.convs1.2.weight_g', 'vae.vocoder.head.resblocks.2.convs1.2.weight_v', 'vae.vocoder.head.resblocks.2.convs2.0.bias', 'vae.vocoder.head.resblocks.2.convs2.0.weight_g', 'vae.vocoder.head.resblocks.2.convs2.0.weight_v', 'vae.vocoder.head.resblocks.2.convs2.1.bias', 'vae.vocoder.head.resblocks.2.convs2.1.weight_g', 'vae.vocoder.head.resblocks.2.convs2.1.weight_v', 'vae.vocoder.head.resblocks.2.convs2.2.bias', 'vae.vocoder.head.resblocks.2.convs2.2.weight_g', 'vae.vocoder.head.resblocks.2.convs2.2.weight_v', 'vae.vocoder.head.resblocks.3.convs1.0.bias', 'vae.vocoder.head.resblocks.3.convs1.0.weight_g', 'vae.vocoder.head.resblocks.3.convs1.0.weight_v', 'vae.vocoder.head.resblocks.3.convs1.1.bias', 'vae.vocoder.head.resblocks.3.convs1.1.weight_g', 'vae.vocoder.head.resblocks.3.convs1.1.weight_v', 'vae.vocoder.head.resblocks.3.convs1.2.bias', 'vae.vocoder.head.resblocks.3.convs1.2.weight_g', 'vae.vocoder.head.resblocks.3.convs1.2.weight_v', 'vae.vocoder.head.resblocks.3.convs2.0.bias', 'vae.vocoder.head.resblocks.3.convs2.0.weight_g', 'vae.vocoder.head.resblocks.3.convs2.0.weight_v', 'vae.vocoder.head.resblocks.3.convs2.1.bias', 'vae.vocoder.head.resblocks.3.convs2.1.weight_g', 'vae.vocoder.head.resblocks.3.convs2.1.weight_v', 'vae.vocoder.head.resblocks.3.convs2.2.bias', 'vae.vocoder.head.resblocks.3.convs2.2.weight_g', 'vae.vocoder.head.resblocks.3.convs2.2.weight_v', 'vae.vocoder.head.resblocks.4.convs1.0.bias', 'vae.vocoder.head.resblocks.4.convs1.0.weight_g', 'vae.vocoder.head.resblocks.4.convs1.0.weight_v', 'vae.vocoder.head.resblocks.4.convs1.1.bias', 'vae.vocoder.head.resblocks.4.convs1.1.weight_g', 'vae.vocoder.head.resblocks.4.convs1.1.weight_v', 'vae.vocoder.head.resblocks.4.convs1.2.bias', 'vae.vocoder.head.resblocks.4.convs1.2.weight_g', 'vae.vocoder.head.resblocks.4.convs1.2.weight_v', 'vae.vocoder.head.resblocks.4.convs2.0.bias', 'vae.vocoder.head.resblocks.4.convs2.0.weight_g', 'vae.vocoder.head.resblocks.4.convs2.0.weight_v', 'vae.vocoder.head.resblocks.4.convs2.1.bias', 'vae.vocoder.head.resblocks.4.convs2.1.weight_g', 'vae.vocoder.head.resblocks.4.convs2.1.weight_v', 'vae.vocoder.head.resblocks.4.convs2.2.bias', 'vae.vocoder.head.resblocks.4.convs2.2.weight_g', 'vae.vocoder.head.resblocks.4.convs2.2.weight_v', 'vae.vocoder.head.resblocks.5.convs1.0.bias', 'vae.vocoder.head.resblocks.5.convs1.0.weight_g', 'vae.vocoder.head.resblocks.5.convs1.0.weight_v', 'vae.vocoder.head.resblocks.5.convs1.1.bias', 'vae.vocoder.head.resblocks.5.convs1.1.weight_g', 'vae.vocoder.head.resblocks.5.convs1.1.weight_v', 'vae.vocoder.head.resblocks.5.convs1.2.bias', 'vae.vocoder.head.resblocks.5.convs1.2.weight_g', 'vae.vocoder.head.resblocks.5.convs1.2.weight_v', 'vae.vocoder.head.resblocks.5.convs2.0.bias', 'vae.vocoder.head.resblocks.5.convs2.0.weight_g', 'vae.vocoder.head.resblocks.5.convs2.0.weight_v', 'vae.vocoder.head.resblocks.5.convs2.1.bias', 'vae.vocoder.head.resblocks.5.convs2.1.weight_g', 'vae.vocoder.head.resblocks.5.convs2.1.weight_v', 'vae.vocoder.head.resblocks.5.convs2.2.bias', 'vae.vocoder.head.resblocks.5.convs2.2.weight_g', 'vae.vocoder.head.resblocks.5.convs2.2.weight_v', 'vae.vocoder.head.resblocks.6.convs1.0.bias', 'vae.vocoder.head.resblocks.6.convs1.0.weight_g', 'vae.vocoder.head.resblocks.6.convs1.0.weight_v', 'vae.vocoder.head.resblocks.6.convs1.1.bias', 'vae.vocoder.head.resblocks.6.convs1.1.weight_g', 'vae.vocoder.head.resblocks.6.convs1.1.weight_v', 'vae.vocoder.head.resblocks.6.convs1.2.bias', 'vae.vocoder.head.resblocks.6.convs1.2.weight_g', 'vae.vocoder.head.resblocks.6.convs1.2.weight_v', 'vae.vocoder.head.resblocks.6.convs2.0.bias', 'vae.vocoder.head.resblocks.6.convs2.0.weight_g', 'vae.vocoder.head.resblocks.6.convs2.0.weight_v', 'vae.vocoder.head.resblocks.6.convs2.1.bias', 'vae.vocoder.head.resblocks.6.convs2.1.weight_g', 'vae.vocoder.head.resblocks.6.convs2.1.weight_v', 'vae.vocoder.head.resblocks.6.convs2.2.bias', 'vae.vocoder.head.resblocks.6.convs2.2.weight_g', 'vae.vocoder.head.resblocks.6.convs2.2.weight_v', 'vae.vocoder.head.resblocks.7.convs1.0.bias', 'vae.vocoder.head.resblocks.7.convs1.0.weight_g', 'vae.vocoder.head.resblocks.7.convs1.0.weight_v', 'vae.vocoder.head.resblocks.7.convs1.1.bias', 'vae.vocoder.head.resblocks.7.convs1.1.weight_g', 'vae.vocoder.head.resblocks.7.convs1.1.weight_v', 'vae.vocoder.head.resblocks.7.convs1.2.bias', 'vae.vocoder.head.resblocks.7.convs1.2.weight_g', 'vae.vocoder.head.resblocks.7.convs1.2.weight_v', 'vae.vocoder.head.resblocks.7.convs2.0.bias', 'vae.vocoder.head.resblocks.7.convs2.0.weight_g', 'vae.vocoder.head.resblocks.7.convs2.0.weight_v', 'vae.vocoder.head.resblocks.7.convs2.1.bias', 'vae.vocoder.head.resblocks.7.convs2.1.weight_g', 'vae.vocoder.head.resblocks.7.convs2.1.weight_v', 'vae.vocoder.head.resblocks.7.convs2.2.bias', 'vae.vocoder.head.resblocks.7.convs2.2.weight_g', 'vae.vocoder.head.resblocks.7.convs2.2.weight_v', 'vae.vocoder.head.resblocks.8.convs1.0.bias', 'vae.vocoder.head.resblocks.8.convs1.0.weight_g', 'vae.vocoder.head.resblocks.8.convs1.0.weight_v', 'vae.vocoder.head.resblocks.8.convs1.1.bias', 'vae.vocoder.head.resblocks.8.convs1.1.weight_g', 'vae.vocoder.head.resblocks.8.convs1.1.weight_v', 'vae.vocoder.head.resblocks.8.convs1.2.bias', 'vae.vocoder.head.resblocks.8.convs1.2.weight_g', 'vae.vocoder.head.resblocks.8.convs1.2.weight_v', 'vae.vocoder.head.resblocks.8.convs2.0.bias', 'vae.vocoder.head.resblocks.8.convs2.0.weight_g', 'vae.vocoder.head.resblocks.8.convs2.0.weight_v', 'vae.vocoder.head.resblocks.8.convs2.1.bias', 'vae.vocoder.head.resblocks.8.convs2.1.weight_g', 'vae.vocoder.head.resblocks.8.convs2.1.weight_v', 'vae.vocoder.head.resblocks.8.convs2.2.bias', 'vae.vocoder.head.resblocks.8.convs2.2.weight_g', 'vae.vocoder.head.resblocks.8.convs2.2.weight_v', 'vae.vocoder.head.resblocks.9.convs1.0.bias', 'vae.vocoder.head.resblocks.9.convs1.0.weight_g', 'vae.vocoder.head.resblocks.9.convs1.0.weight_v', 'vae.vocoder.head.resblocks.9.convs1.1.bias', 'vae.vocoder.head.resblocks.9.convs1.1.weight_g', 'vae.vocoder.head.resblocks.9.convs1.1.weight_v', 'vae.vocoder.head.resblocks.9.convs1.2.bias', 'vae.vocoder.head.resblocks.9.convs1.2.weight_g', 'vae.vocoder.head.resblocks.9.convs1.2.weight_v', 'vae.vocoder.head.resblocks.9.convs2.0.bias', 'vae.vocoder.head.resblocks.9.convs2.0.weight_g', 'vae.vocoder.head.resblocks.9.convs2.0.weight_v', 'vae.vocoder.head.resblocks.9.convs2.1.bias', 'vae.vocoder.head.resblocks.9.convs2.1.weight_g', 'vae.vocoder.head.resblocks.9.convs2.1.weight_v', 'vae.vocoder.head.resblocks.9.convs2.2.bias', 'vae.vocoder.head.resblocks.9.convs2.2.weight_g', 'vae.vocoder.head.resblocks.9.convs2.2.weight_v', 'vae.vocoder.head.resblocks.10.convs1.0.bias', 'vae.vocoder.head.resblocks.10.convs1.0.weight_g', 'vae.vocoder.head.resblocks.10.convs1.0.weight_v', 'vae.vocoder.head.resblocks.10.convs1.1.bias', 'vae.vocoder.head.resblocks.10.convs1.1.weight_g', 'vae.vocoder.head.resblocks.10.convs1.1.weight_v', 'vae.vocoder.head.resblocks.10.convs1.2.bias', 'vae.vocoder.head.resblocks.10.convs1.2.weight_g', 'vae.vocoder.head.resblocks.10.convs1.2.weight_v', 'vae.vocoder.head.resblocks.10.convs2.0.bias', 'vae.vocoder.head.resblocks.10.convs2.0.weight_g', 'vae.vocoder.head.resblocks.10.convs2.0.weight_v', 'vae.vocoder.head.resblocks.10.convs2.1.bias', 'vae.vocoder.head.resblocks.10.convs2.1.weight_g', 'vae.vocoder.head.resblocks.10.convs2.1.weight_v', 'vae.vocoder.head.resblocks.10.convs2.2.bias', 'vae.vocoder.head.resblocks.10.convs2.2.weight_g', 'vae.vocoder.head.resblocks.10.convs2.2.weight_v', 'vae.vocoder.head.resblocks.11.convs1.0.bias', 'vae.vocoder.head.resblocks.11.convs1.0.weight_g', 'vae.vocoder.head.resblocks.11.convs1.0.weight_v', 'vae.vocoder.head.resblocks.11.convs1.1.bias', 'vae.vocoder.head.resblocks.11.convs1.1.weight_g', 'vae.vocoder.head.resblocks.11.convs1.1.weight_v', 'vae.vocoder.head.resblocks.11.convs1.2.bias', 'vae.vocoder.head.resblocks.11.convs1.2.weight_g', 'vae.vocoder.head.resblocks.11.convs1.2.weight_v', 'vae.vocoder.head.resblocks.11.convs2.0.bias', 'vae.vocoder.head.resblocks.11.convs2.0.weight_g', 'vae.vocoder.head.resblocks.11.convs2.0.weight_v', 'vae.vocoder.head.resblocks.11.convs2.1.bias', 'vae.vocoder.head.resblocks.11.convs2.1.weight_g', 'vae.vocoder.head.resblocks.11.convs2.1.weight_v', 'vae.vocoder.head.resblocks.11.convs2.2.bias', 'vae.vocoder.head.resblocks.11.convs2.2.weight_g', 'vae.vocoder.head.resblocks.11.convs2.2.weight_v', 'vae.vocoder.head.resblocks.12.convs1.0.bias', 'vae.vocoder.head.resblocks.12.convs1.0.weight_g', 'vae.vocoder.head.resblocks.12.convs1.0.weight_v', 'vae.vocoder.head.resblocks.12.convs1.1.bias', 'vae.vocoder.head.resblocks.12.convs1.1.weight_g', 'vae.vocoder.head.resblocks.12.convs1.1.weight_v', 'vae.vocoder.head.resblocks.12.convs1.2.bias', 'vae.vocoder.head.resblocks.12.convs1.2.weight_g', 'vae.vocoder.head.resblocks.12.convs1.2.weight_v', 'vae.vocoder.head.resblocks.12.convs2.0.bias', 'vae.vocoder.head.resblocks.12.convs2.0.weight_g', 'vae.vocoder.head.resblocks.12.convs2.0.weight_v', 'vae.vocoder.head.resblocks.12.convs2.1.bias', 'vae.vocoder.head.resblocks.12.convs2.1.weight_g', 'vae.vocoder.head.resblocks.12.convs2.1.weight_v', 'vae.vocoder.head.resblocks.12.convs2.2.bias', 'vae.vocoder.head.resblocks.12.convs2.2.weight_g', 'vae.vocoder.head.resblocks.12.convs2.2.weight_v', 'vae.vocoder.head.resblocks.13.convs1.0.bias', 'vae.vocoder.head.resblocks.13.convs1.0.weight_g', 'vae.vocoder.head.resblocks.13.convs1.0.weight_v', 'vae.vocoder.head.resblocks.13.convs1.1.bias', 'vae.vocoder.head.resblocks.13.convs1.1.weight_g', 'vae.vocoder.head.resblocks.13.convs1.1.weight_v', 'vae.vocoder.head.resblocks.13.convs1.2.bias', 'vae.vocoder.head.resblocks.13.convs1.2.weight_g', 'vae.vocoder.head.resblocks.13.convs1.2.weight_v', 'vae.vocoder.head.resblocks.13.convs2.0.bias', 'vae.vocoder.head.resblocks.13.convs2.0.weight_g', 'vae.vocoder.head.resblocks.13.convs2.0.weight_v', 'vae.vocoder.head.resblocks.13.convs2.1.bias', 'vae.vocoder.head.resblocks.13.convs2.1.weight_g', 'vae.vocoder.head.resblocks.13.convs2.1.weight_v', 'vae.vocoder.head.resblocks.13.convs2.2.bias', 'vae.vocoder.head.resblocks.13.convs2.2.weight_g', 'vae.vocoder.head.resblocks.13.convs2.2.weight_v', 'vae.vocoder.head.resblocks.14.convs1.0.bias', 'vae.vocoder.head.resblocks.14.convs1.0.weight_g', 'vae.vocoder.head.resblocks.14.convs1.0.weight_v', 'vae.vocoder.head.resblocks.14.convs1.1.bias', 'vae.vocoder.head.resblocks.14.convs1.1.weight_g', 'vae.vocoder.head.resblocks.14.convs1.1.weight_v', 'vae.vocoder.head.resblocks.14.convs1.2.bias', 'vae.vocoder.head.resblocks.14.convs1.2.weight_g', 'vae.vocoder.head.resblocks.14.convs1.2.weight_v', 'vae.vocoder.head.resblocks.14.convs2.0.bias', 'vae.vocoder.head.resblocks.14.convs2.0.weight_g', 'vae.vocoder.head.resblocks.14.convs2.0.weight_v', 'vae.vocoder.head.resblocks.14.convs2.1.bias', 'vae.vocoder.head.resblocks.14.convs2.1.weight_g', 'vae.vocoder.head.resblocks.14.convs2.1.weight_v', 'vae.vocoder.head.resblocks.14.convs2.2.bias', 'vae.vocoder.head.resblocks.14.convs2.2.weight_g', 'vae.vocoder.head.resblocks.14.convs2.2.weight_v', 'vae.vocoder.head.resblocks.15.convs1.0.bias', 'vae.vocoder.head.resblocks.15.convs1.0.weight_g', 'vae.vocoder.head.resblocks.15.convs1.0.weight_v', 'vae.vocoder.head.resblocks.15.convs1.1.bias', 'vae.vocoder.head.resblocks.15.convs1.1.weight_g', 'vae.vocoder.head.resblocks.15.convs1.1.weight_v', 'vae.vocoder.head.resblocks.15.convs1.2.bias', 'vae.vocoder.head.resblocks.15.convs1.2.weight_g', 'vae.vocoder.head.resblocks.15.convs1.2.weight_v', 'vae.vocoder.head.resblocks.15.convs2.0.bias', 'vae.vocoder.head.resblocks.15.convs2.0.weight_g', 'vae.vocoder.head.resblocks.15.convs2.0.weight_v', 'vae.vocoder.head.resblocks.15.convs2.1.bias', 'vae.vocoder.head.resblocks.15.convs2.1.weight_g', 'vae.vocoder.head.resblocks.15.convs2.1.weight_v', 'vae.vocoder.head.resblocks.15.convs2.2.bias', 'vae.vocoder.head.resblocks.15.convs2.2.weight_g', 'vae.vocoder.head.resblocks.15.convs2.2.weight_v', 'vae.vocoder.head.resblocks.16.convs1.0.bias', 'vae.vocoder.head.resblocks.16.convs1.0.weight_g', 'vae.vocoder.head.resblocks.16.convs1.0.weight_v', 'vae.vocoder.head.resblocks.16.convs1.1.bias', 'vae.vocoder.head.resblocks.16.convs1.1.weight_g', 'vae.vocoder.head.resblocks.16.convs1.1.weight_v', 'vae.vocoder.head.resblocks.16.convs1.2.bias', 'vae.vocoder.head.resblocks.16.convs1.2.weight_g', 'vae.vocoder.head.resblocks.16.convs1.2.weight_v', 'vae.vocoder.head.resblocks.16.convs2.0.bias', 'vae.vocoder.head.resblocks.16.convs2.0.weight_g', 'vae.vocoder.head.resblocks.16.convs2.0.weight_v', 'vae.vocoder.head.resblocks.16.convs2.1.bias', 'vae.vocoder.head.resblocks.16.convs2.1.weight_g', 'vae.vocoder.head.resblocks.16.convs2.1.weight_v', 'vae.vocoder.head.resblocks.16.convs2.2.bias', 'vae.vocoder.head.resblocks.16.convs2.2.weight_g', 'vae.vocoder.head.resblocks.16.convs2.2.weight_v', 'vae.vocoder.head.resblocks.17.convs1.0.bias', 'vae.vocoder.head.resblocks.17.convs1.0.weight_g', 'vae.vocoder.head.resblocks.17.convs1.0.weight_v', 'vae.vocoder.head.resblocks.17.convs1.1.bias', 'vae.vocoder.head.resblocks.17.convs1.1.weight_g', 'vae.vocoder.head.resblocks.17.convs1.1.weight_v', 'vae.vocoder.head.resblocks.17.convs1.2.bias', 'vae.vocoder.head.resblocks.17.convs1.2.weight_g', 'vae.vocoder.head.resblocks.17.convs1.2.weight_v', 'vae.vocoder.head.resblocks.17.convs2.0.bias', 'vae.vocoder.head.resblocks.17.convs2.0.weight_g', 'vae.vocoder.head.resblocks.17.convs2.0.weight_v', 'vae.vocoder.head.resblocks.17.convs2.1.bias', 'vae.vocoder.head.resblocks.17.convs2.1.weight_g', 'vae.vocoder.head.resblocks.17.convs2.1.weight_v', 'vae.vocoder.head.resblocks.17.convs2.2.bias', 'vae.vocoder.head.resblocks.17.convs2.2.weight_g', 'vae.vocoder.head.resblocks.17.convs2.2.weight_v', 'vae.vocoder.head.resblocks.18.convs1.0.bias', 'vae.vocoder.head.resblocks.18.convs1.0.weight_g', 'vae.vocoder.head.resblocks.18.convs1.0.weight_v', 'vae.vocoder.head.resblocks.18.convs1.1.bias', 'vae.vocoder.head.resblocks.18.convs1.1.weight_g', 'vae.vocoder.head.resblocks.18.convs1.1.weight_v', 'vae.vocoder.head.resblocks.18.convs1.2.bias', 'vae.vocoder.head.resblocks.18.convs1.2.weight_g', 'vae.vocoder.head.resblocks.18.convs1.2.weight_v', 'vae.vocoder.head.resblocks.18.convs2.0.bias', 'vae.vocoder.head.resblocks.18.convs2.0.weight_g', 'vae.vocoder.head.resblocks.18.convs2.0.weight_v', 'vae.vocoder.head.resblocks.18.convs2.1.bias', 'vae.vocoder.head.resblocks.18.convs2.1.weight_g', 'vae.vocoder.head.resblocks.18.convs2.1.weight_v', 'vae.vocoder.head.resblocks.18.convs2.2.bias', 'vae.vocoder.head.resblocks.18.convs2.2.weight_g', 'vae.vocoder.head.resblocks.18.convs2.2.weight_v', 'vae.vocoder.head.resblocks.19.convs1.0.bias', 'vae.vocoder.head.resblocks.19.convs1.0.weight_g', 'vae.vocoder.head.resblocks.19.convs1.0.weight_v', 'vae.vocoder.head.resblocks.19.convs1.1.bias', 'vae.vocoder.head.resblocks.19.convs1.1.weight_g', 'vae.vocoder.head.resblocks.19.convs1.1.weight_v', 'vae.vocoder.head.resblocks.19.convs1.2.bias', 'vae.vocoder.head.resblocks.19.convs1.2.weight_g', 'vae.vocoder.head.resblocks.19.convs1.2.weight_v', 'vae.vocoder.head.resblocks.19.convs2.0.bias', 'vae.vocoder.head.resblocks.19.convs2.0.weight_g', 'vae.vocoder.head.resblocks.19.convs2.0.weight_v', 'vae.vocoder.head.resblocks.19.convs2.1.bias', 'vae.vocoder.head.resblocks.19.convs2.1.weight_g', 'vae.vocoder.head.resblocks.19.convs2.1.weight_v', 'vae.vocoder.head.resblocks.19.convs2.2.bias', 'vae.vocoder.head.resblocks.19.convs2.2.weight_g', 'vae.vocoder.head.resblocks.19.convs2.2.weight_v', 'vae.vocoder.head.resblocks.20.convs1.0.bias', 'vae.vocoder.head.resblocks.20.convs1.0.weight_g', 'vae.vocoder.head.resblocks.20.convs1.0.weight_v', 'vae.vocoder.head.resblocks.20.convs1.1.bias', 'vae.vocoder.head.resblocks.20.convs1.1.weight_g', 'vae.vocoder.head.resblocks.20.convs1.1.weight_v', 'vae.vocoder.head.resblocks.20.convs1.2.bias', 'vae.vocoder.head.resblocks.20.convs1.2.weight_g', 'vae.vocoder.head.resblocks.20.convs1.2.weight_v', 'vae.vocoder.head.resblocks.20.convs2.0.bias', 'vae.vocoder.head.resblocks.20.convs2.0.weight_g', 'vae.vocoder.head.resblocks.20.convs2.0.weight_v', 'vae.vocoder.head.resblocks.20.convs2.1.bias', 'vae.vocoder.head.resblocks.20.convs2.1.weight_g', 'vae.vocoder.head.resblocks.20.convs2.1.weight_v', 'vae.vocoder.head.resblocks.20.convs2.2.bias', 'vae.vocoder.head.resblocks.20.convs2.2.weight_g', 'vae.vocoder.head.resblocks.20.convs2.2.weight_v', 'vae.vocoder.head.resblocks.21.convs1.0.bias', 'vae.vocoder.head.resblocks.21.convs1.0.weight_g', 'vae.vocoder.head.resblocks.21.convs1.0.weight_v', 'vae.vocoder.head.resblocks.21.convs1.1.bias', 'vae.vocoder.head.resblocks.21.convs1.1.weight_g', 'vae.vocoder.head.resblocks.21.convs1.1.weight_v', 'vae.vocoder.head.resblocks.21.convs1.2.bias', 'vae.vocoder.head.resblocks.21.convs1.2.weight_g', 'vae.vocoder.head.resblocks.21.convs1.2.weight_v', 'vae.vocoder.head.resblocks.21.convs2.0.bias', 'vae.vocoder.head.resblocks.21.convs2.0.weight_g', 'vae.vocoder.head.resblocks.21.convs2.0.weight_v', 'vae.vocoder.head.resblocks.21.convs2.1.bias', 'vae.vocoder.head.resblocks.21.convs2.1.weight_g', 'vae.vocoder.head.resblocks.21.convs2.1.weight_v', 'vae.vocoder.head.resblocks.21.convs2.2.bias', 'vae.vocoder.head.resblocks.21.convs2.2.weight_g', 'vae.vocoder.head.resblocks.21.convs2.2.weight_v', 'vae.vocoder.head.resblocks.22.convs1.0.bias', 'vae.vocoder.head.resblocks.22.convs1.0.weight_g', 'vae.vocoder.head.resblocks.22.convs1.0.weight_v', 'vae.vocoder.head.resblocks.22.convs1.1.bias', 'vae.vocoder.head.resblocks.22.convs1.1.weight_g', 'vae.vocoder.head.resblocks.22.convs1.1.weight_v', 'vae.vocoder.head.resblocks.22.convs1.2.bias', 'vae.vocoder.head.resblocks.22.convs1.2.weight_g', 'vae.vocoder.head.resblocks.22.convs1.2.weight_v', 'vae.vocoder.head.resblocks.22.convs2.0.bias', 'vae.vocoder.head.resblocks.22.convs2.0.weight_g', 'vae.vocoder.head.resblocks.22.convs2.0.weight_v', 'vae.vocoder.head.resblocks.22.convs2.1.bias', 'vae.vocoder.head.resblocks.22.convs2.1.weight_g', 'vae.vocoder.head.resblocks.22.convs2.1.weight_v', 'vae.vocoder.head.resblocks.22.convs2.2.bias', 'vae.vocoder.head.resblocks.22.convs2.2.weight_g', 'vae.vocoder.head.resblocks.22.convs2.2.weight_v', 'vae.vocoder.head.resblocks.23.convs1.0.bias', 'vae.vocoder.head.resblocks.23.convs1.0.weight_g', 'vae.vocoder.head.resblocks.23.convs1.0.weight_v', 'vae.vocoder.head.resblocks.23.convs1.1.bias', 'vae.vocoder.head.resblocks.23.convs1.1.weight_g', 'vae.vocoder.head.resblocks.23.convs1.1.weight_v', 'vae.vocoder.head.resblocks.23.convs1.2.bias', 'vae.vocoder.head.resblocks.23.convs1.2.weight_g', 'vae.vocoder.head.resblocks.23.convs1.2.weight_v', 'vae.vocoder.head.resblocks.23.convs2.0.bias', 'vae.vocoder.head.resblocks.23.convs2.0.weight_g', 'vae.vocoder.head.resblocks.23.convs2.0.weight_v', 'vae.vocoder.head.resblocks.23.convs2.1.bias', 'vae.vocoder.head.resblocks.23.convs2.1.weight_g', 'vae.vocoder.head.resblocks.23.convs2.1.weight_v', 'vae.vocoder.head.resblocks.23.convs2.2.bias', 'vae.vocoder.head.resblocks.23.convs2.2.weight_g', 'vae.vocoder.head.resblocks.23.convs2.2.weight_v', 'vae.vocoder.head.resblocks.24.convs1.0.bias', 'vae.vocoder.head.resblocks.24.convs1.0.weight_g', 'vae.vocoder.head.resblocks.24.convs1.0.weight_v', 'vae.vocoder.head.resblocks.24.convs1.1.bias', 'vae.vocoder.head.resblocks.24.convs1.1.weight_g', 'vae.vocoder.head.resblocks.24.convs1.1.weight_v', 'vae.vocoder.head.resblocks.24.convs1.2.bias', 'vae.vocoder.head.resblocks.24.convs1.2.weight_g', 'vae.vocoder.head.resblocks.24.convs1.2.weight_v', 'vae.vocoder.head.resblocks.24.convs2.0.bias', 'vae.vocoder.head.resblocks.24.convs2.0.weight_g', 'vae.vocoder.head.resblocks.24.convs2.0.weight_v', 'vae.vocoder.head.resblocks.24.convs2.1.bias', 'vae.vocoder.head.resblocks.24.convs2.1.weight_g', 'vae.vocoder.head.resblocks.24.convs2.1.weight_v', 'vae.vocoder.head.resblocks.24.convs2.2.bias', 'vae.vocoder.head.resblocks.24.convs2.2.weight_g', 'vae.vocoder.head.resblocks.24.convs2.2.weight_v', 'vae.vocoder.head.resblocks.25.convs1.0.bias', 'vae.vocoder.head.resblocks.25.convs1.0.weight_g', 'vae.vocoder.head.resblocks.25.convs1.0.weight_v', 'vae.vocoder.head.resblocks.25.convs1.1.bias', 'vae.vocoder.head.resblocks.25.convs1.1.weight_g', 'vae.vocoder.head.resblocks.25.convs1.1.weight_v', 'vae.vocoder.head.resblocks.25.convs1.2.bias', 'vae.vocoder.head.resblocks.25.convs1.2.weight_g', 'vae.vocoder.head.resblocks.25.convs1.2.weight_v', 'vae.vocoder.head.resblocks.25.convs2.0.bias', 'vae.vocoder.head.resblocks.25.convs2.0.weight_g', 'vae.vocoder.head.resblocks.25.convs2.0.weight_v', 'vae.vocoder.head.resblocks.25.convs2.1.bias', 'vae.vocoder.head.resblocks.25.convs2.1.weight_g', 'vae.vocoder.head.resblocks.25.convs2.1.weight_v', 'vae.vocoder.head.resblocks.25.convs2.2.bias', 'vae.vocoder.head.resblocks.25.convs2.2.weight_g', 'vae.vocoder.head.resblocks.25.convs2.2.weight_v', 'vae.vocoder.head.resblocks.26.convs1.0.bias', 'vae.vocoder.head.resblocks.26.convs1.0.weight_g', 'vae.vocoder.head.resblocks.26.convs1.0.weight_v', 'vae.vocoder.head.resblocks.26.convs1.1.bias', 'vae.vocoder.head.resblocks.26.convs1.1.weight_g', 'vae.vocoder.head.resblocks.26.convs1.1.weight_v', 'vae.vocoder.head.resblocks.26.convs1.2.bias', 'vae.vocoder.head.resblocks.26.convs1.2.weight_g', 'vae.vocoder.head.resblocks.26.convs1.2.weight_v', 'vae.vocoder.head.resblocks.26.convs2.0.bias', 'vae.vocoder.head.resblocks.26.convs2.0.weight_g', 'vae.vocoder.head.resblocks.26.convs2.0.weight_v', 'vae.vocoder.head.resblocks.26.convs2.1.bias', 'vae.vocoder.head.resblocks.26.convs2.1.weight_g', 'vae.vocoder.head.resblocks.26.convs2.1.weight_v', 'vae.vocoder.head.resblocks.26.convs2.2.bias', 'vae.vocoder.head.resblocks.26.convs2.2.weight_g', 'vae.vocoder.head.resblocks.26.convs2.2.weight_v', 'vae.vocoder.head.resblocks.27.convs1.0.bias', 'vae.vocoder.head.resblocks.27.convs1.0.weight_g', 'vae.vocoder.head.resblocks.27.convs1.0.weight_v', 'vae.vocoder.head.resblocks.27.convs1.1.bias', 'vae.vocoder.head.resblocks.27.convs1.1.weight_g', 'vae.vocoder.head.resblocks.27.convs1.1.weight_v', 'vae.vocoder.head.resblocks.27.convs1.2.bias', 'vae.vocoder.head.resblocks.27.convs1.2.weight_g', 'vae.vocoder.head.resblocks.27.convs1.2.weight_v', 'vae.vocoder.head.resblocks.27.convs2.0.bias', 'vae.vocoder.head.resblocks.27.convs2.0.weight_g', 'vae.vocoder.head.resblocks.27.convs2.0.weight_v', 'vae.vocoder.head.resblocks.27.convs2.1.bias', 'vae.vocoder.head.resblocks.27.convs2.1.weight_g', 'vae.vocoder.head.resblocks.27.convs2.1.weight_v', 'vae.vocoder.head.resblocks.27.convs2.2.bias', 'vae.vocoder.head.resblocks.27.convs2.2.weight_g', 'vae.vocoder.head.resblocks.27.convs2.2.weight_v', 'vae.vocoder.head.conv_post.bias', 'vae.vocoder.head.conv_post.weight_g', 'vae.vocoder.head.conv_post.weight_v', 'transformers.transformer_blocks.0.scale_shift_table', 'transformers.transformer_blocks.0.attn.to_q.weight', 'transformers.transformer_blocks.0.attn.to_q.bias', 'transformers.transformer_blocks.0.attn.to_k.weight', 'transformers.transformer_blocks.0.attn.to_k.bias', 'transformers.transformer_blocks.0.attn.to_v.weight', 'transformers.transformer_blocks.0.attn.to_v.bias', 'transformers.transformer_blocks.0.attn.to_out.0.weight', 'transformers.transformer_blocks.0.attn.to_out.0.bias', 'transformers.transformer_blocks.0.cross_attn.to_q.weight', 'transformers.transformer_blocks.0.cross_attn.to_q.bias', 'transformers.transformer_blocks.0.cross_attn.to_k.weight', 'transformers.transformer_blocks.0.cross_attn.to_k.bias', 'transformers.transformer_blocks.0.cross_attn.to_v.weight', 'transformers.transformer_blocks.0.cross_attn.to_v.bias', 'transformers.transformer_blocks.0.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.0.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.0.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.0.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.0.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.0.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.0.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.0.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.0.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.0.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.0.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.0.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.0.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.0.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.0.ff.point_conv.conv.weight', 'transformers.transformer_blocks.1.scale_shift_table', 'transformers.transformer_blocks.1.attn.to_q.weight', 'transformers.transformer_blocks.1.attn.to_q.bias', 'transformers.transformer_blocks.1.attn.to_k.weight', 'transformers.transformer_blocks.1.attn.to_k.bias', 'transformers.transformer_blocks.1.attn.to_v.weight', 'transformers.transformer_blocks.1.attn.to_v.bias', 'transformers.transformer_blocks.1.attn.to_out.0.weight', 'transformers.transformer_blocks.1.attn.to_out.0.bias', 'transformers.transformer_blocks.1.cross_attn.to_q.weight', 'transformers.transformer_blocks.1.cross_attn.to_q.bias', 'transformers.transformer_blocks.1.cross_attn.to_k.weight', 'transformers.transformer_blocks.1.cross_attn.to_k.bias', 'transformers.transformer_blocks.1.cross_attn.to_v.weight', 'transformers.transformer_blocks.1.cross_attn.to_v.bias', 'transformers.transformer_blocks.1.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.1.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.1.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.1.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.1.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.1.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.1.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.1.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.1.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.1.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.1.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.1.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.1.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.1.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.1.ff.point_conv.conv.weight', 'transformers.transformer_blocks.2.scale_shift_table', 'transformers.transformer_blocks.2.attn.to_q.weight', 'transformers.transformer_blocks.2.attn.to_q.bias', 'transformers.transformer_blocks.2.attn.to_k.weight', 'transformers.transformer_blocks.2.attn.to_k.bias', 'transformers.transformer_blocks.2.attn.to_v.weight', 'transformers.transformer_blocks.2.attn.to_v.bias', 'transformers.transformer_blocks.2.attn.to_out.0.weight', 'transformers.transformer_blocks.2.attn.to_out.0.bias', 'transformers.transformer_blocks.2.cross_attn.to_q.weight', 'transformers.transformer_blocks.2.cross_attn.to_q.bias', 'transformers.transformer_blocks.2.cross_attn.to_k.weight', 'transformers.transformer_blocks.2.cross_attn.to_k.bias', 'transformers.transformer_blocks.2.cross_attn.to_v.weight', 'transformers.transformer_blocks.2.cross_attn.to_v.bias', 'transformers.transformer_blocks.2.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.2.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.2.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.2.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.2.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.2.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.2.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.2.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.2.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.2.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.2.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.2.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.2.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.2.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.2.ff.point_conv.conv.weight', 'transformers.transformer_blocks.3.scale_shift_table', 'transformers.transformer_blocks.3.attn.to_q.weight', 'transformers.transformer_blocks.3.attn.to_q.bias', 'transformers.transformer_blocks.3.attn.to_k.weight', 'transformers.transformer_blocks.3.attn.to_k.bias', 'transformers.transformer_blocks.3.attn.to_v.weight', 'transformers.transformer_blocks.3.attn.to_v.bias', 'transformers.transformer_blocks.3.attn.to_out.0.weight', 'transformers.transformer_blocks.3.attn.to_out.0.bias', 'transformers.transformer_blocks.3.cross_attn.to_q.weight', 'transformers.transformer_blocks.3.cross_attn.to_q.bias', 'transformers.transformer_blocks.3.cross_attn.to_k.weight', 'transformers.transformer_blocks.3.cross_attn.to_k.bias', 'transformers.transformer_blocks.3.cross_attn.to_v.weight', 'transformers.transformer_blocks.3.cross_attn.to_v.bias', 'transformers.transformer_blocks.3.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.3.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.3.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.3.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.3.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.3.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.3.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.3.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.3.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.3.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.3.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.3.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.3.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.3.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.3.ff.point_conv.conv.weight', 'transformers.transformer_blocks.4.scale_shift_table', 'transformers.transformer_blocks.4.attn.to_q.weight', 'transformers.transformer_blocks.4.attn.to_q.bias', 'transformers.transformer_blocks.4.attn.to_k.weight', 'transformers.transformer_blocks.4.attn.to_k.bias', 'transformers.transformer_blocks.4.attn.to_v.weight', 'transformers.transformer_blocks.4.attn.to_v.bias', 'transformers.transformer_blocks.4.attn.to_out.0.weight', 'transformers.transformer_blocks.4.attn.to_out.0.bias', 'transformers.transformer_blocks.4.cross_attn.to_q.weight', 'transformers.transformer_blocks.4.cross_attn.to_q.bias', 'transformers.transformer_blocks.4.cross_attn.to_k.weight', 'transformers.transformer_blocks.4.cross_attn.to_k.bias', 'transformers.transformer_blocks.4.cross_attn.to_v.weight', 'transformers.transformer_blocks.4.cross_attn.to_v.bias', 'transformers.transformer_blocks.4.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.4.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.4.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.4.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.4.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.4.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.4.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.4.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.4.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.4.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.4.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.4.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.4.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.4.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.4.ff.point_conv.conv.weight', 'transformers.transformer_blocks.5.scale_shift_table', 'transformers.transformer_blocks.5.attn.to_q.weight', 'transformers.transformer_blocks.5.attn.to_q.bias', 'transformers.transformer_blocks.5.attn.to_k.weight', 'transformers.transformer_blocks.5.attn.to_k.bias', 'transformers.transformer_blocks.5.attn.to_v.weight', 'transformers.transformer_blocks.5.attn.to_v.bias', 'transformers.transformer_blocks.5.attn.to_out.0.weight', 'transformers.transformer_blocks.5.attn.to_out.0.bias', 'transformers.transformer_blocks.5.cross_attn.to_q.weight', 'transformers.transformer_blocks.5.cross_attn.to_q.bias', 'transformers.transformer_blocks.5.cross_attn.to_k.weight', 'transformers.transformer_blocks.5.cross_attn.to_k.bias', 'transformers.transformer_blocks.5.cross_attn.to_v.weight', 'transformers.transformer_blocks.5.cross_attn.to_v.bias', 'transformers.transformer_blocks.5.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.5.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.5.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.5.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.5.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.5.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.5.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.5.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.5.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.5.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.5.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.5.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.5.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.5.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.5.ff.point_conv.conv.weight', 'transformers.transformer_blocks.6.scale_shift_table', 'transformers.transformer_blocks.6.attn.to_q.weight', 'transformers.transformer_blocks.6.attn.to_q.bias', 'transformers.transformer_blocks.6.attn.to_k.weight', 'transformers.transformer_blocks.6.attn.to_k.bias', 'transformers.transformer_blocks.6.attn.to_v.weight', 'transformers.transformer_blocks.6.attn.to_v.bias', 'transformers.transformer_blocks.6.attn.to_out.0.weight', 'transformers.transformer_blocks.6.attn.to_out.0.bias', 'transformers.transformer_blocks.6.cross_attn.to_q.weight', 'transformers.transformer_blocks.6.cross_attn.to_q.bias', 'transformers.transformer_blocks.6.cross_attn.to_k.weight', 'transformers.transformer_blocks.6.cross_attn.to_k.bias', 'transformers.transformer_blocks.6.cross_attn.to_v.weight', 'transformers.transformer_blocks.6.cross_attn.to_v.bias', 'transformers.transformer_blocks.6.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.6.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.6.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.6.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.6.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.6.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.6.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.6.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.6.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.6.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.6.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.6.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.6.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.6.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.6.ff.point_conv.conv.weight', 'transformers.transformer_blocks.7.scale_shift_table', 'transformers.transformer_blocks.7.attn.to_q.weight', 'transformers.transformer_blocks.7.attn.to_q.bias', 'transformers.transformer_blocks.7.attn.to_k.weight', 'transformers.transformer_blocks.7.attn.to_k.bias', 'transformers.transformer_blocks.7.attn.to_v.weight', 'transformers.transformer_blocks.7.attn.to_v.bias', 'transformers.transformer_blocks.7.attn.to_out.0.weight', 'transformers.transformer_blocks.7.attn.to_out.0.bias', 'transformers.transformer_blocks.7.cross_attn.to_q.weight', 'transformers.transformer_blocks.7.cross_attn.to_q.bias', 'transformers.transformer_blocks.7.cross_attn.to_k.weight', 'transformers.transformer_blocks.7.cross_attn.to_k.bias', 'transformers.transformer_blocks.7.cross_attn.to_v.weight', 'transformers.transformer_blocks.7.cross_attn.to_v.bias', 'transformers.transformer_blocks.7.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.7.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.7.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.7.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.7.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.7.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.7.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.7.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.7.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.7.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.7.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.7.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.7.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.7.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.7.ff.point_conv.conv.weight', 'transformers.transformer_blocks.8.scale_shift_table', 'transformers.transformer_blocks.8.attn.to_q.weight', 'transformers.transformer_blocks.8.attn.to_q.bias', 'transformers.transformer_blocks.8.attn.to_k.weight', 'transformers.transformer_blocks.8.attn.to_k.bias', 'transformers.transformer_blocks.8.attn.to_v.weight', 'transformers.transformer_blocks.8.attn.to_v.bias', 'transformers.transformer_blocks.8.attn.to_out.0.weight', 'transformers.transformer_blocks.8.attn.to_out.0.bias', 'transformers.transformer_blocks.8.cross_attn.to_q.weight', 'transformers.transformer_blocks.8.cross_attn.to_q.bias', 'transformers.transformer_blocks.8.cross_attn.to_k.weight', 'transformers.transformer_blocks.8.cross_attn.to_k.bias', 'transformers.transformer_blocks.8.cross_attn.to_v.weight', 'transformers.transformer_blocks.8.cross_attn.to_v.bias', 'transformers.transformer_blocks.8.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.8.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.8.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.8.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.8.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.8.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.8.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.8.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.8.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.8.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.8.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.8.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.8.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.8.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.8.ff.point_conv.conv.weight', 'transformers.transformer_blocks.9.scale_shift_table', 'transformers.transformer_blocks.9.attn.to_q.weight', 'transformers.transformer_blocks.9.attn.to_q.bias', 'transformers.transformer_blocks.9.attn.to_k.weight', 'transformers.transformer_blocks.9.attn.to_k.bias', 'transformers.transformer_blocks.9.attn.to_v.weight', 'transformers.transformer_blocks.9.attn.to_v.bias', 'transformers.transformer_blocks.9.attn.to_out.0.weight', 'transformers.transformer_blocks.9.attn.to_out.0.bias', 'transformers.transformer_blocks.9.cross_attn.to_q.weight', 'transformers.transformer_blocks.9.cross_attn.to_q.bias', 'transformers.transformer_blocks.9.cross_attn.to_k.weight', 'transformers.transformer_blocks.9.cross_attn.to_k.bias', 'transformers.transformer_blocks.9.cross_attn.to_v.weight', 'transformers.transformer_blocks.9.cross_attn.to_v.bias', 'transformers.transformer_blocks.9.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.9.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.9.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.9.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.9.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.9.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.9.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.9.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.9.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.9.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.9.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.9.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.9.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.9.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.9.ff.point_conv.conv.weight', 'transformers.transformer_blocks.10.scale_shift_table', 'transformers.transformer_blocks.10.attn.to_q.weight', 'transformers.transformer_blocks.10.attn.to_q.bias', 'transformers.transformer_blocks.10.attn.to_k.weight', 'transformers.transformer_blocks.10.attn.to_k.bias', 'transformers.transformer_blocks.10.attn.to_v.weight', 'transformers.transformer_blocks.10.attn.to_v.bias', 'transformers.transformer_blocks.10.attn.to_out.0.weight', 'transformers.transformer_blocks.10.attn.to_out.0.bias', 'transformers.transformer_blocks.10.cross_attn.to_q.weight', 'transformers.transformer_blocks.10.cross_attn.to_q.bias', 'transformers.transformer_blocks.10.cross_attn.to_k.weight', 'transformers.transformer_blocks.10.cross_attn.to_k.bias', 'transformers.transformer_blocks.10.cross_attn.to_v.weight', 'transformers.transformer_blocks.10.cross_attn.to_v.bias', 'transformers.transformer_blocks.10.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.10.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.10.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.10.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.10.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.10.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.10.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.10.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.10.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.10.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.10.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.10.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.10.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.10.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.10.ff.point_conv.conv.weight', 'transformers.transformer_blocks.11.scale_shift_table', 'transformers.transformer_blocks.11.attn.to_q.weight', 'transformers.transformer_blocks.11.attn.to_q.bias', 'transformers.transformer_blocks.11.attn.to_k.weight', 'transformers.transformer_blocks.11.attn.to_k.bias', 'transformers.transformer_blocks.11.attn.to_v.weight', 'transformers.transformer_blocks.11.attn.to_v.bias', 'transformers.transformer_blocks.11.attn.to_out.0.weight', 'transformers.transformer_blocks.11.attn.to_out.0.bias', 'transformers.transformer_blocks.11.cross_attn.to_q.weight', 'transformers.transformer_blocks.11.cross_attn.to_q.bias', 'transformers.transformer_blocks.11.cross_attn.to_k.weight', 'transformers.transformer_blocks.11.cross_attn.to_k.bias', 'transformers.transformer_blocks.11.cross_attn.to_v.weight', 'transformers.transformer_blocks.11.cross_attn.to_v.bias', 'transformers.transformer_blocks.11.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.11.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.11.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.11.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.11.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.11.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.11.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.11.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.11.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.11.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.11.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.11.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.11.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.11.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.11.ff.point_conv.conv.weight', 'transformers.transformer_blocks.12.scale_shift_table', 'transformers.transformer_blocks.12.attn.to_q.weight', 'transformers.transformer_blocks.12.attn.to_q.bias', 'transformers.transformer_blocks.12.attn.to_k.weight', 'transformers.transformer_blocks.12.attn.to_k.bias', 'transformers.transformer_blocks.12.attn.to_v.weight', 'transformers.transformer_blocks.12.attn.to_v.bias', 'transformers.transformer_blocks.12.attn.to_out.0.weight', 'transformers.transformer_blocks.12.attn.to_out.0.bias', 'transformers.transformer_blocks.12.cross_attn.to_q.weight', 'transformers.transformer_blocks.12.cross_attn.to_q.bias', 'transformers.transformer_blocks.12.cross_attn.to_k.weight', 'transformers.transformer_blocks.12.cross_attn.to_k.bias', 'transformers.transformer_blocks.12.cross_attn.to_v.weight', 'transformers.transformer_blocks.12.cross_attn.to_v.bias', 'transformers.transformer_blocks.12.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.12.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.12.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.12.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.12.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.12.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.12.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.12.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.12.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.12.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.12.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.12.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.12.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.12.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.12.ff.point_conv.conv.weight', 'transformers.transformer_blocks.13.scale_shift_table', 'transformers.transformer_blocks.13.attn.to_q.weight', 'transformers.transformer_blocks.13.attn.to_q.bias', 'transformers.transformer_blocks.13.attn.to_k.weight', 'transformers.transformer_blocks.13.attn.to_k.bias', 'transformers.transformer_blocks.13.attn.to_v.weight', 'transformers.transformer_blocks.13.attn.to_v.bias', 'transformers.transformer_blocks.13.attn.to_out.0.weight', 'transformers.transformer_blocks.13.attn.to_out.0.bias', 'transformers.transformer_blocks.13.cross_attn.to_q.weight', 'transformers.transformer_blocks.13.cross_attn.to_q.bias', 'transformers.transformer_blocks.13.cross_attn.to_k.weight', 'transformers.transformer_blocks.13.cross_attn.to_k.bias', 'transformers.transformer_blocks.13.cross_attn.to_v.weight', 'transformers.transformer_blocks.13.cross_attn.to_v.bias', 'transformers.transformer_blocks.13.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.13.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.13.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.13.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.13.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.13.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.13.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.13.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.13.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.13.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.13.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.13.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.13.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.13.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.13.ff.point_conv.conv.weight', 'transformers.transformer_blocks.14.scale_shift_table', 'transformers.transformer_blocks.14.attn.to_q.weight', 'transformers.transformer_blocks.14.attn.to_q.bias', 'transformers.transformer_blocks.14.attn.to_k.weight', 'transformers.transformer_blocks.14.attn.to_k.bias', 'transformers.transformer_blocks.14.attn.to_v.weight', 'transformers.transformer_blocks.14.attn.to_v.bias', 'transformers.transformer_blocks.14.attn.to_out.0.weight', 'transformers.transformer_blocks.14.attn.to_out.0.bias', 'transformers.transformer_blocks.14.cross_attn.to_q.weight', 'transformers.transformer_blocks.14.cross_attn.to_q.bias', 'transformers.transformer_blocks.14.cross_attn.to_k.weight', 'transformers.transformer_blocks.14.cross_attn.to_k.bias', 'transformers.transformer_blocks.14.cross_attn.to_v.weight', 'transformers.transformer_blocks.14.cross_attn.to_v.bias', 'transformers.transformer_blocks.14.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.14.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.14.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.14.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.14.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.14.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.14.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.14.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.14.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.14.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.14.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.14.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.14.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.14.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.14.ff.point_conv.conv.weight', 'transformers.transformer_blocks.15.scale_shift_table', 'transformers.transformer_blocks.15.attn.to_q.weight', 'transformers.transformer_blocks.15.attn.to_q.bias', 'transformers.transformer_blocks.15.attn.to_k.weight', 'transformers.transformer_blocks.15.attn.to_k.bias', 'transformers.transformer_blocks.15.attn.to_v.weight', 'transformers.transformer_blocks.15.attn.to_v.bias', 'transformers.transformer_blocks.15.attn.to_out.0.weight', 'transformers.transformer_blocks.15.attn.to_out.0.bias', 'transformers.transformer_blocks.15.cross_attn.to_q.weight', 'transformers.transformer_blocks.15.cross_attn.to_q.bias', 'transformers.transformer_blocks.15.cross_attn.to_k.weight', 'transformers.transformer_blocks.15.cross_attn.to_k.bias', 'transformers.transformer_blocks.15.cross_attn.to_v.weight', 'transformers.transformer_blocks.15.cross_attn.to_v.bias', 'transformers.transformer_blocks.15.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.15.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.15.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.15.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.15.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.15.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.15.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.15.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.15.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.15.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.15.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.15.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.15.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.15.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.15.ff.point_conv.conv.weight', 'transformers.transformer_blocks.16.scale_shift_table', 'transformers.transformer_blocks.16.attn.to_q.weight', 'transformers.transformer_blocks.16.attn.to_q.bias', 'transformers.transformer_blocks.16.attn.to_k.weight', 'transformers.transformer_blocks.16.attn.to_k.bias', 'transformers.transformer_blocks.16.attn.to_v.weight', 'transformers.transformer_blocks.16.attn.to_v.bias', 'transformers.transformer_blocks.16.attn.to_out.0.weight', 'transformers.transformer_blocks.16.attn.to_out.0.bias', 'transformers.transformer_blocks.16.cross_attn.to_q.weight', 'transformers.transformer_blocks.16.cross_attn.to_q.bias', 'transformers.transformer_blocks.16.cross_attn.to_k.weight', 'transformers.transformer_blocks.16.cross_attn.to_k.bias', 'transformers.transformer_blocks.16.cross_attn.to_v.weight', 'transformers.transformer_blocks.16.cross_attn.to_v.bias', 'transformers.transformer_blocks.16.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.16.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.16.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.16.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.16.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.16.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.16.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.16.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.16.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.16.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.16.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.16.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.16.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.16.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.16.ff.point_conv.conv.weight', 'transformers.transformer_blocks.17.scale_shift_table', 'transformers.transformer_blocks.17.attn.to_q.weight', 'transformers.transformer_blocks.17.attn.to_q.bias', 'transformers.transformer_blocks.17.attn.to_k.weight', 'transformers.transformer_blocks.17.attn.to_k.bias', 'transformers.transformer_blocks.17.attn.to_v.weight', 'transformers.transformer_blocks.17.attn.to_v.bias', 'transformers.transformer_blocks.17.attn.to_out.0.weight', 'transformers.transformer_blocks.17.attn.to_out.0.bias', 'transformers.transformer_blocks.17.cross_attn.to_q.weight', 'transformers.transformer_blocks.17.cross_attn.to_q.bias', 'transformers.transformer_blocks.17.cross_attn.to_k.weight', 'transformers.transformer_blocks.17.cross_attn.to_k.bias', 'transformers.transformer_blocks.17.cross_attn.to_v.weight', 'transformers.transformer_blocks.17.cross_attn.to_v.bias', 'transformers.transformer_blocks.17.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.17.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.17.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.17.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.17.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.17.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.17.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.17.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.17.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.17.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.17.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.17.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.17.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.17.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.17.ff.point_conv.conv.weight', 'transformers.transformer_blocks.18.scale_shift_table', 'transformers.transformer_blocks.18.attn.to_q.weight', 'transformers.transformer_blocks.18.attn.to_q.bias', 'transformers.transformer_blocks.18.attn.to_k.weight', 'transformers.transformer_blocks.18.attn.to_k.bias', 'transformers.transformer_blocks.18.attn.to_v.weight', 'transformers.transformer_blocks.18.attn.to_v.bias', 'transformers.transformer_blocks.18.attn.to_out.0.weight', 'transformers.transformer_blocks.18.attn.to_out.0.bias', 'transformers.transformer_blocks.18.cross_attn.to_q.weight', 'transformers.transformer_blocks.18.cross_attn.to_q.bias', 'transformers.transformer_blocks.18.cross_attn.to_k.weight', 'transformers.transformer_blocks.18.cross_attn.to_k.bias', 'transformers.transformer_blocks.18.cross_attn.to_v.weight', 'transformers.transformer_blocks.18.cross_attn.to_v.bias', 'transformers.transformer_blocks.18.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.18.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.18.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.18.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.18.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.18.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.18.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.18.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.18.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.18.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.18.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.18.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.18.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.18.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.18.ff.point_conv.conv.weight', 'transformers.transformer_blocks.19.scale_shift_table', 'transformers.transformer_blocks.19.attn.to_q.weight', 'transformers.transformer_blocks.19.attn.to_q.bias', 'transformers.transformer_blocks.19.attn.to_k.weight', 'transformers.transformer_blocks.19.attn.to_k.bias', 'transformers.transformer_blocks.19.attn.to_v.weight', 'transformers.transformer_blocks.19.attn.to_v.bias', 'transformers.transformer_blocks.19.attn.to_out.0.weight', 'transformers.transformer_blocks.19.attn.to_out.0.bias', 'transformers.transformer_blocks.19.cross_attn.to_q.weight', 'transformers.transformer_blocks.19.cross_attn.to_q.bias', 'transformers.transformer_blocks.19.cross_attn.to_k.weight', 'transformers.transformer_blocks.19.cross_attn.to_k.bias', 'transformers.transformer_blocks.19.cross_attn.to_v.weight', 'transformers.transformer_blocks.19.cross_attn.to_v.bias', 'transformers.transformer_blocks.19.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.19.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.19.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.19.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.19.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.19.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.19.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.19.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.19.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.19.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.19.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.19.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.19.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.19.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.19.ff.point_conv.conv.weight', 'transformers.transformer_blocks.20.scale_shift_table', 'transformers.transformer_blocks.20.attn.to_q.weight', 'transformers.transformer_blocks.20.attn.to_q.bias', 'transformers.transformer_blocks.20.attn.to_k.weight', 'transformers.transformer_blocks.20.attn.to_k.bias', 'transformers.transformer_blocks.20.attn.to_v.weight', 'transformers.transformer_blocks.20.attn.to_v.bias', 'transformers.transformer_blocks.20.attn.to_out.0.weight', 'transformers.transformer_blocks.20.attn.to_out.0.bias', 'transformers.transformer_blocks.20.cross_attn.to_q.weight', 'transformers.transformer_blocks.20.cross_attn.to_q.bias', 'transformers.transformer_blocks.20.cross_attn.to_k.weight', 'transformers.transformer_blocks.20.cross_attn.to_k.bias', 'transformers.transformer_blocks.20.cross_attn.to_v.weight', 'transformers.transformer_blocks.20.cross_attn.to_v.bias', 'transformers.transformer_blocks.20.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.20.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.20.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.20.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.20.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.20.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.20.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.20.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.20.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.20.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.20.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.20.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.20.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.20.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.20.ff.point_conv.conv.weight', 'transformers.transformer_blocks.21.scale_shift_table', 'transformers.transformer_blocks.21.attn.to_q.weight', 'transformers.transformer_blocks.21.attn.to_q.bias', 'transformers.transformer_blocks.21.attn.to_k.weight', 'transformers.transformer_blocks.21.attn.to_k.bias', 'transformers.transformer_blocks.21.attn.to_v.weight', 'transformers.transformer_blocks.21.attn.to_v.bias', 'transformers.transformer_blocks.21.attn.to_out.0.weight', 'transformers.transformer_blocks.21.attn.to_out.0.bias', 'transformers.transformer_blocks.21.cross_attn.to_q.weight', 'transformers.transformer_blocks.21.cross_attn.to_q.bias', 'transformers.transformer_blocks.21.cross_attn.to_k.weight', 'transformers.transformer_blocks.21.cross_attn.to_k.bias', 'transformers.transformer_blocks.21.cross_attn.to_v.weight', 'transformers.transformer_blocks.21.cross_attn.to_v.bias', 'transformers.transformer_blocks.21.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.21.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.21.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.21.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.21.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.21.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.21.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.21.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.21.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.21.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.21.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.21.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.21.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.21.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.21.ff.point_conv.conv.weight', 'transformers.transformer_blocks.22.scale_shift_table', 'transformers.transformer_blocks.22.attn.to_q.weight', 'transformers.transformer_blocks.22.attn.to_q.bias', 'transformers.transformer_blocks.22.attn.to_k.weight', 'transformers.transformer_blocks.22.attn.to_k.bias', 'transformers.transformer_blocks.22.attn.to_v.weight', 'transformers.transformer_blocks.22.attn.to_v.bias', 'transformers.transformer_blocks.22.attn.to_out.0.weight', 'transformers.transformer_blocks.22.attn.to_out.0.bias', 'transformers.transformer_blocks.22.cross_attn.to_q.weight', 'transformers.transformer_blocks.22.cross_attn.to_q.bias', 'transformers.transformer_blocks.22.cross_attn.to_k.weight', 'transformers.transformer_blocks.22.cross_attn.to_k.bias', 'transformers.transformer_blocks.22.cross_attn.to_v.weight', 'transformers.transformer_blocks.22.cross_attn.to_v.bias', 'transformers.transformer_blocks.22.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.22.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.22.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.22.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.22.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.22.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.22.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.22.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.22.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.22.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.22.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.22.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.22.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.22.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.22.ff.point_conv.conv.weight', 'transformers.transformer_blocks.23.scale_shift_table', 'transformers.transformer_blocks.23.attn.to_q.weight', 'transformers.transformer_blocks.23.attn.to_q.bias', 'transformers.transformer_blocks.23.attn.to_k.weight', 'transformers.transformer_blocks.23.attn.to_k.bias', 'transformers.transformer_blocks.23.attn.to_v.weight', 'transformers.transformer_blocks.23.attn.to_v.bias', 'transformers.transformer_blocks.23.attn.to_out.0.weight', 'transformers.transformer_blocks.23.attn.to_out.0.bias', 'transformers.transformer_blocks.23.cross_attn.to_q.weight', 'transformers.transformer_blocks.23.cross_attn.to_q.bias', 'transformers.transformer_blocks.23.cross_attn.to_k.weight', 'transformers.transformer_blocks.23.cross_attn.to_k.bias', 'transformers.transformer_blocks.23.cross_attn.to_v.weight', 'transformers.transformer_blocks.23.cross_attn.to_v.bias', 'transformers.transformer_blocks.23.cross_attn.add_k_proj.weight', 'transformers.transformer_blocks.23.cross_attn.add_k_proj.bias', 'transformers.transformer_blocks.23.cross_attn.add_v_proj.weight', 'transformers.transformer_blocks.23.cross_attn.add_v_proj.bias', 'transformers.transformer_blocks.23.cross_attn.add_q_proj.weight', 'transformers.transformer_blocks.23.cross_attn.add_q_proj.bias', 'transformers.transformer_blocks.23.cross_attn.to_out.0.weight', 'transformers.transformer_blocks.23.cross_attn.to_out.0.bias', 'transformers.transformer_blocks.23.cross_attn.to_add_out.weight', 'transformers.transformer_blocks.23.cross_attn.to_add_out.bias', 'transformers.transformer_blocks.23.ff.inverted_conv.conv.weight', 'transformers.transformer_blocks.23.ff.inverted_conv.conv.bias', 'transformers.transformer_blocks.23.ff.depth_conv.conv.weight', 'transformers.transformer_blocks.23.ff.depth_conv.conv.bias', 'transformers.transformer_blocks.23.ff.point_conv.conv.weight', 'transformers.timestep_embedder.linear_1.weight', 'transformers.timestep_embedder.linear_1.bias', 'transformers.timestep_embedder.linear_2.weight', 'transformers.timestep_embedder.linear_2.bias', 'transformers.t_block.1.weight', 'transformers.t_block.1.bias', 'transformers.speaker_embedder.weight', 'transformers.speaker_embedder.bias', 'transformers.genre_embedder.weight', 'transformers.genre_embedder.bias', 'transformers.lyric_embs.weight', 'transformers.lyric_encoder.embed.out.0.weight', 'transformers.lyric_encoder.embed.out.0.bias', 'transformers.lyric_encoder.embed.out.1.weight', 'transformers.lyric_encoder.embed.out.1.bias', 'transformers.lyric_encoder.after_norm.weight', 'transformers.lyric_encoder.after_norm.bias', 'transformers.lyric_encoder.encoders.0.self_attn.pos_bias_u', 'transformers.lyric_encoder.encoders.0.self_attn.pos_bias_v', 'transformers.lyric_encoder.encoders.0.self_attn.linear_q.weight', 'transformers.lyric_encoder.encoders.0.self_attn.linear_q.bias', 'transformers.lyric_encoder.encoders.0.self_attn.linear_k.weight', 'transformers.lyric_encoder.encoders.0.self_attn.linear_k.bias', 'transformers.lyric_encoder.encoders.0.self_attn.linear_v.weight', 'transformers.lyric_encoder.encoders.0.self_attn.linear_v.bias', 'transformers.lyric_encoder.encoders.0.self_attn.linear_out.weight', 'transformers.lyric_encoder.encoders.0.self_attn.linear_out.bias', 'transformers.lyric_encoder.encoders.0.self_attn.linear_pos.weight', 'transformers.lyric_encoder.encoders.0.feed_forward.w_1.weight', 'transformers.lyric_encoder.encoders.0.feed_forward.w_1.bias', 'transformers.lyric_encoder.encoders.0.feed_forward.w_2.weight', 'transformers.lyric_encoder.encoders.0.feed_forward.w_2.bias', 'transformers.lyric_encoder.encoders.0.norm_ff.weight', 'transformers.lyric_encoder.encoders.0.norm_ff.bias', 'transformers.lyric_encoder.encoders.0.norm_mha.weight', 'transformers.lyric_encoder.encoders.0.norm_mha.bias', 'transformers.lyric_encoder.encoders.1.self_attn.pos_bias_u', 'transformers.lyric_encoder.encoders.1.self_attn.pos_bias_v', 'transformers.lyric_encoder.encoders.1.self_attn.linear_q.weight', 'transformers.lyric_encoder.encoders.1.self_attn.linear_q.bias', 'transformers.lyric_encoder.encoders.1.self_attn.linear_k.weight', 'transformers.lyric_encoder.encoders.1.self_attn.linear_k.bias', 'transformers.lyric_encoder.encoders.1.self_attn.linear_v.weight', 'transformers.lyric_encoder.encoders.1.self_attn.linear_v.bias', 'transformers.lyric_encoder.encoders.1.self_attn.linear_out.weight', 'transformers.lyric_encoder.encoders.1.self_attn.linear_out.bias', 'transformers.lyric_encoder.encoders.1.self_attn.linear_pos.weight', 'transformers.lyric_encoder.encoders.1.feed_forward.w_1.weight', 'transformers.lyric_encoder.encoders.1.feed_forward.w_1.bias', 'transformers.lyric_encoder.encoders.1.feed_forward.w_2.weight', 'transformers.lyric_encoder.encoders.1.feed_forward.w_2.bias', 'transformers.lyric_encoder.encoders.1.norm_ff.weight', 'transformers.lyric_encoder.encoders.1.norm_ff.bias', 'transformers.lyric_encoder.encoders.1.norm_mha.weight', 'transformers.lyric_encoder.encoders.1.norm_mha.bias', 'transformers.lyric_encoder.encoders.2.self_attn.pos_bias_u', 'transformers.lyric_encoder.encoders.2.self_attn.pos_bias_v', 'transformers.lyric_encoder.encoders.2.self_attn.linear_q.weight', 'transformers.lyric_encoder.encoders.2.self_attn.linear_q.bias', 'transformers.lyric_encoder.encoders.2.self_attn.linear_k.weight', 'transformers.lyric_encoder.encoders.2.self_attn.linear_k.bias', 'transformers.lyric_encoder.encoders.2.self_attn.linear_v.weight', 'transformers.lyric_encoder.encoders.2.self_attn.linear_v.bias', 'transformers.lyric_encoder.encoders.2.self_attn.linear_out.weight', 'transformers.lyric_encoder.encoders.2.self_attn.linear_out.bias', 'transformers.lyric_encoder.encoders.2.self_attn.linear_pos.weight', 'transformers.lyric_encoder.encoders.2.feed_forward.w_1.weight', 'transformers.lyric_encoder.encoders.2.feed_forward.w_1.bias', 'transformers.lyric_encoder.encoders.2.feed_forward.w_2.weight', 'transformers.lyric_encoder.encoders.2.feed_forward.w_2.bias', 'transformers.lyric_encoder.encoders.2.norm_ff.weight', 'transformers.lyric_encoder.encoders.2.norm_ff.bias', 'transformers.lyric_encoder.encoders.2.norm_mha.weight', 'transformers.lyric_encoder.encoders.2.norm_mha.bias', 'transformers.lyric_encoder.encoders.3.self_attn.pos_bias_u', 'transformers.lyric_encoder.encoders.3.self_attn.pos_bias_v', 'transformers.lyric_encoder.encoders.3.self_attn.linear_q.weight', 'transformers.lyric_encoder.encoders.3.self_attn.linear_q.bias', 'transformers.lyric_encoder.encoders.3.self_attn.linear_k.weight', 'transformers.lyric_encoder.encoders.3.self_attn.linear_k.bias', 'transformers.lyric_encoder.encoders.3.self_attn.linear_v.weight', 'transformers.lyric_encoder.encoders.3.self_attn.linear_v.bias', 'transformers.lyric_encoder.encoders.3.self_attn.linear_out.weight', 'transformers.lyric_encoder.encoders.3.self_attn.linear_out.bias', 'transformers.lyric_encoder.encoders.3.self_attn.linear_pos.weight', 'transformers.lyric_encoder.encoders.3.feed_forward.w_1.weight', 'transformers.lyric_encoder.encoders.3.feed_forward.w_1.bias', 'transformers.lyric_encoder.encoders.3.feed_forward.w_2.weight', 'transformers.lyric_encoder.encoders.3.feed_forward.w_2.bias', 'transformers.lyric_encoder.encoders.3.norm_ff.weight', 'transformers.lyric_encoder.encoders.3.norm_ff.bias', 'transformers.lyric_encoder.encoders.3.norm_mha.weight', 'transformers.lyric_encoder.encoders.3.norm_mha.bias', 'transformers.lyric_encoder.encoders.4.self_attn.pos_bias_u', 'transformers.lyric_encoder.encoders.4.self_attn.pos_bias_v', 'transformers.lyric_encoder.encoders.4.self_attn.linear_q.weight', 'transformers.lyric_encoder.encoders.4.self_attn.linear_q.bias', 'transformers.lyric_encoder.encoders.4.self_attn.linear_k.weight', 'transformers.lyric_encoder.encoders.4.self_attn.linear_k.bias', 'transformers.lyric_encoder.encoders.4.self_attn.linear_v.weight', 'transformers.lyric_encoder.encoders.4.self_attn.linear_v.bias', 'transformers.lyric_encoder.encoders.4.self_attn.linear_out.weight', 'transformers.lyric_encoder.encoders.4.self_attn.linear_out.bias', 'transformers.lyric_encoder.encoders.4.self_attn.linear_pos.weight', 'transformers.lyric_encoder.encoders.4.feed_forward.w_1.weight', 'transformers.lyric_encoder.encoders.4.feed_forward.w_1.bias', 'transformers.lyric_encoder.encoders.4.feed_forward.w_2.weight', 'transformers.lyric_encoder.encoders.4.feed_forward.w_2.bias', 'transformers.lyric_encoder.encoders.4.norm_ff.weight', 'transformers.lyric_encoder.encoders.4.norm_ff.bias', 'transformers.lyric_encoder.encoders.4.norm_mha.weight', 'transformers.lyric_encoder.encoders.4.norm_mha.bias', 'transformers.lyric_encoder.encoders.5.self_attn.pos_bias_u', 'transformers.lyric_encoder.encoders.5.self_attn.pos_bias_v', 'transformers.lyric_encoder.encoders.5.self_attn.linear_q.weight', 'transformers.lyric_encoder.encoders.5.self_attn.linear_q.bias', 'transformers.lyric_encoder.encoders.5.self_attn.linear_k.weight', 'transformers.lyric_encoder.encoders.5.self_attn.linear_k.bias', 'transformers.lyric_encoder.encoders.5.self_attn.linear_v.weight', 'transformers.lyric_encoder.encoders.5.self_attn.linear_v.bias', 'transformers.lyric_encoder.encoders.5.self_attn.linear_out.weight', 'transformers.lyric_encoder.encoders.5.self_attn.linear_out.bias', 'transformers.lyric_encoder.encoders.5.self_attn.linear_pos.weight', 'transformers.lyric_encoder.encoders.5.feed_forward.w_1.weight', 'transformers.lyric_encoder.encoders.5.feed_forward.w_1.bias', 'transformers.lyric_encoder.encoders.5.feed_forward.w_2.weight', 'transformers.lyric_encoder.encoders.5.feed_forward.w_2.bias', 'transformers.lyric_encoder.encoders.5.norm_ff.weight', 'transformers.lyric_encoder.encoders.5.norm_ff.bias', 'transformers.lyric_encoder.encoders.5.norm_mha.weight', 'transformers.lyric_encoder.encoders.5.norm_mha.bias', 'transformers.lyric_proj.weight', 'transformers.lyric_proj.bias', 'transformers.projectors.0.0.weight', 'transformers.projectors.0.0.bias', 'transformers.projectors.0.2.weight', 'transformers.projectors.0.2.bias', 'transformers.projectors.0.4.weight', 'transformers.projectors.0.4.bias', 'transformers.projectors.1.0.weight', 'transformers.projectors.1.0.bias', 'transformers.projectors.1.2.weight', 'transformers.projectors.1.2.bias', 'transformers.projectors.1.4.weight', 'transformers.projectors.1.4.bias', 'transformers.proj_in.early_conv_layers.0.weight', 'transformers.proj_in.early_conv_layers.0.bias', 'transformers.proj_in.early_conv_layers.1.weight', 'transformers.proj_in.early_conv_layers.1.bias', 'transformers.proj_in.early_conv_layers.2.weight', 'transformers.proj_in.early_conv_layers.2.bias', 'transformers.final_layer.scale_shift_table', 'transformers.final_layer.linear.weight', 'transformers.final_layer.linear.bias', 'lyric_processor.lyric_text_model.encoder.embed_tokens.weight'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_checkpoint = {k.replace(\"transformers.\", \"\"):v for k, v in checkpoint.items() if k.startswith(\"transformers.\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sag_train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.fusic_transformer import FusicTransformer2DModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"models/config.json\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusic_model = FusicTransformer2DModel(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusic_model.load_state_dict(transformers_checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusic_model = fusic_model.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusic_model.save_pretrained(\"checkpoints/fusic_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoencoderDC\n",
    "\n",
    "DEFAULT_PRETRAINED_PATH = \"./checkpoints/music_dcae_f8c8\"\n",
    "dcae = AutoencoderDC.from_pretrained(DEFAULT_PRETRAINED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcae = dcae.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcae.save_pretrained(\"checkpoints/music_dcae_f8c8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sag_train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from music_dcae.music_vocoder import ADaMoSHiFiGANV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sag_train/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "/vepfs-d-data/q-ace/repo/gongjunmin/ACEFlow3/music_dcae/music_vocoder.py:540: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt_state = torch.load(checkpoint_path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "vocoder = ADaMoSHiFiGANV1(checkpoint_path=\"/root/sag_train/checkpoints/music_vocoder.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "vocoder = vocoder.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder.save_pretrained(\"checkpoints/music_vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sag_train/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from music_dcae.music_dcae_pipeline import MusicDCAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint were not used when initializing MusicDCAE: \n",
      " ['dcae.decoder.conv_in.bias, dcae.decoder.conv_in.weight, dcae.decoder.conv_out.bias, dcae.decoder.conv_out.weight, dcae.decoder.norm_out.bias, dcae.decoder.norm_out.weight, dcae.decoder.up_blocks.0.0.conv.bias, dcae.decoder.up_blocks.0.0.conv.weight, dcae.decoder.up_blocks.0.1.conv1.bias, dcae.decoder.up_blocks.0.1.conv1.weight, dcae.decoder.up_blocks.0.1.conv2.weight, dcae.decoder.up_blocks.0.1.norm.bias, dcae.decoder.up_blocks.0.1.norm.weight, dcae.decoder.up_blocks.0.2.conv1.bias, dcae.decoder.up_blocks.0.2.conv1.weight, dcae.decoder.up_blocks.0.2.conv2.weight, dcae.decoder.up_blocks.0.2.norm.bias, dcae.decoder.up_blocks.0.2.norm.weight, dcae.decoder.up_blocks.0.3.conv1.bias, dcae.decoder.up_blocks.0.3.conv1.weight, dcae.decoder.up_blocks.0.3.conv2.weight, dcae.decoder.up_blocks.0.3.norm.bias, dcae.decoder.up_blocks.0.3.norm.weight, dcae.decoder.up_blocks.1.0.conv.bias, dcae.decoder.up_blocks.1.0.conv.weight, dcae.decoder.up_blocks.1.1.conv1.bias, dcae.decoder.up_blocks.1.1.conv1.weight, dcae.decoder.up_blocks.1.1.conv2.weight, dcae.decoder.up_blocks.1.1.norm.bias, dcae.decoder.up_blocks.1.1.norm.weight, dcae.decoder.up_blocks.1.2.conv1.bias, dcae.decoder.up_blocks.1.2.conv1.weight, dcae.decoder.up_blocks.1.2.conv2.weight, dcae.decoder.up_blocks.1.2.norm.bias, dcae.decoder.up_blocks.1.2.norm.weight, dcae.decoder.up_blocks.1.3.conv1.bias, dcae.decoder.up_blocks.1.3.conv1.weight, dcae.decoder.up_blocks.1.3.conv2.weight, dcae.decoder.up_blocks.1.3.norm.bias, dcae.decoder.up_blocks.1.3.norm.weight, dcae.decoder.up_blocks.2.0.conv.bias, dcae.decoder.up_blocks.2.0.conv.weight, dcae.decoder.up_blocks.2.1.conv1.bias, dcae.decoder.up_blocks.2.1.conv1.weight, dcae.decoder.up_blocks.2.1.conv2.weight, dcae.decoder.up_blocks.2.1.norm.bias, dcae.decoder.up_blocks.2.1.norm.weight, dcae.decoder.up_blocks.2.2.conv1.bias, dcae.decoder.up_blocks.2.2.conv1.weight, dcae.decoder.up_blocks.2.2.conv2.weight, dcae.decoder.up_blocks.2.2.norm.bias, dcae.decoder.up_blocks.2.2.norm.weight, dcae.decoder.up_blocks.2.3.conv1.bias, dcae.decoder.up_blocks.2.3.conv1.weight, dcae.decoder.up_blocks.2.3.conv2.weight, dcae.decoder.up_blocks.2.3.norm.bias, dcae.decoder.up_blocks.2.3.norm.weight, dcae.decoder.up_blocks.3.0.attn.norm_out.bias, dcae.decoder.up_blocks.3.0.attn.norm_out.weight, dcae.decoder.up_blocks.3.0.attn.to_k.weight, dcae.decoder.up_blocks.3.0.attn.to_out.weight, dcae.decoder.up_blocks.3.0.attn.to_q.weight, dcae.decoder.up_blocks.3.0.attn.to_qkv_multiscale.0.proj_in.weight, dcae.decoder.up_blocks.3.0.attn.to_qkv_multiscale.0.proj_out.weight, dcae.decoder.up_blocks.3.0.attn.to_v.weight, dcae.decoder.up_blocks.3.0.conv_out.conv_depth.bias, dcae.decoder.up_blocks.3.0.conv_out.conv_depth.weight, dcae.decoder.up_blocks.3.0.conv_out.conv_inverted.bias, dcae.decoder.up_blocks.3.0.conv_out.conv_inverted.weight, dcae.decoder.up_blocks.3.0.conv_out.conv_point.weight, dcae.decoder.up_blocks.3.0.conv_out.norm.bias, dcae.decoder.up_blocks.3.0.conv_out.norm.weight, dcae.decoder.up_blocks.3.1.attn.norm_out.bias, dcae.decoder.up_blocks.3.1.attn.norm_out.weight, dcae.decoder.up_blocks.3.1.attn.to_k.weight, dcae.decoder.up_blocks.3.1.attn.to_out.weight, dcae.decoder.up_blocks.3.1.attn.to_q.weight, dcae.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight, dcae.decoder.up_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight, dcae.decoder.up_blocks.3.1.attn.to_v.weight, dcae.decoder.up_blocks.3.1.conv_out.conv_depth.bias, dcae.decoder.up_blocks.3.1.conv_out.conv_depth.weight, dcae.decoder.up_blocks.3.1.conv_out.conv_inverted.bias, dcae.decoder.up_blocks.3.1.conv_out.conv_inverted.weight, dcae.decoder.up_blocks.3.1.conv_out.conv_point.weight, dcae.decoder.up_blocks.3.1.conv_out.norm.bias, dcae.decoder.up_blocks.3.1.conv_out.norm.weight, dcae.decoder.up_blocks.3.2.attn.norm_out.bias, dcae.decoder.up_blocks.3.2.attn.norm_out.weight, dcae.decoder.up_blocks.3.2.attn.to_k.weight, dcae.decoder.up_blocks.3.2.attn.to_out.weight, dcae.decoder.up_blocks.3.2.attn.to_q.weight, dcae.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight, dcae.decoder.up_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight, dcae.decoder.up_blocks.3.2.attn.to_v.weight, dcae.decoder.up_blocks.3.2.conv_out.conv_depth.bias, dcae.decoder.up_blocks.3.2.conv_out.conv_depth.weight, dcae.decoder.up_blocks.3.2.conv_out.conv_inverted.bias, dcae.decoder.up_blocks.3.2.conv_out.conv_inverted.weight, dcae.decoder.up_blocks.3.2.conv_out.conv_point.weight, dcae.decoder.up_blocks.3.2.conv_out.norm.bias, dcae.decoder.up_blocks.3.2.conv_out.norm.weight, dcae.encoder.conv_in.bias, dcae.encoder.conv_in.weight, dcae.encoder.conv_out.bias, dcae.encoder.conv_out.weight, dcae.encoder.down_blocks.0.0.conv1.bias, dcae.encoder.down_blocks.0.0.conv1.weight, dcae.encoder.down_blocks.0.0.conv2.weight, dcae.encoder.down_blocks.0.0.norm.bias, dcae.encoder.down_blocks.0.0.norm.weight, dcae.encoder.down_blocks.0.1.conv1.bias, dcae.encoder.down_blocks.0.1.conv1.weight, dcae.encoder.down_blocks.0.1.conv2.weight, dcae.encoder.down_blocks.0.1.norm.bias, dcae.encoder.down_blocks.0.1.norm.weight, dcae.encoder.down_blocks.0.2.conv.bias, dcae.encoder.down_blocks.0.2.conv.weight, dcae.encoder.down_blocks.1.0.conv1.bias, dcae.encoder.down_blocks.1.0.conv1.weight, dcae.encoder.down_blocks.1.0.conv2.weight, dcae.encoder.down_blocks.1.0.norm.bias, dcae.encoder.down_blocks.1.0.norm.weight, dcae.encoder.down_blocks.1.1.conv1.bias, dcae.encoder.down_blocks.1.1.conv1.weight, dcae.encoder.down_blocks.1.1.conv2.weight, dcae.encoder.down_blocks.1.1.norm.bias, dcae.encoder.down_blocks.1.1.norm.weight, dcae.encoder.down_blocks.1.2.conv.bias, dcae.encoder.down_blocks.1.2.conv.weight, dcae.encoder.down_blocks.2.0.conv1.bias, dcae.encoder.down_blocks.2.0.conv1.weight, dcae.encoder.down_blocks.2.0.conv2.weight, dcae.encoder.down_blocks.2.0.norm.bias, dcae.encoder.down_blocks.2.0.norm.weight, dcae.encoder.down_blocks.2.1.conv1.bias, dcae.encoder.down_blocks.2.1.conv1.weight, dcae.encoder.down_blocks.2.1.conv2.weight, dcae.encoder.down_blocks.2.1.norm.bias, dcae.encoder.down_blocks.2.1.norm.weight, dcae.encoder.down_blocks.2.2.conv1.bias, dcae.encoder.down_blocks.2.2.conv1.weight, dcae.encoder.down_blocks.2.2.conv2.weight, dcae.encoder.down_blocks.2.2.norm.bias, dcae.encoder.down_blocks.2.2.norm.weight, dcae.encoder.down_blocks.2.3.conv.bias, dcae.encoder.down_blocks.2.3.conv.weight, dcae.encoder.down_blocks.3.0.attn.norm_out.bias, dcae.encoder.down_blocks.3.0.attn.norm_out.weight, dcae.encoder.down_blocks.3.0.attn.to_k.weight, dcae.encoder.down_blocks.3.0.attn.to_out.weight, dcae.encoder.down_blocks.3.0.attn.to_q.weight, dcae.encoder.down_blocks.3.0.attn.to_qkv_multiscale.0.proj_in.weight, dcae.encoder.down_blocks.3.0.attn.to_qkv_multiscale.0.proj_out.weight, dcae.encoder.down_blocks.3.0.attn.to_v.weight, dcae.encoder.down_blocks.3.0.conv_out.conv_depth.bias, dcae.encoder.down_blocks.3.0.conv_out.conv_depth.weight, dcae.encoder.down_blocks.3.0.conv_out.conv_inverted.bias, dcae.encoder.down_blocks.3.0.conv_out.conv_inverted.weight, dcae.encoder.down_blocks.3.0.conv_out.conv_point.weight, dcae.encoder.down_blocks.3.0.conv_out.norm.bias, dcae.encoder.down_blocks.3.0.conv_out.norm.weight, dcae.encoder.down_blocks.3.1.attn.norm_out.bias, dcae.encoder.down_blocks.3.1.attn.norm_out.weight, dcae.encoder.down_blocks.3.1.attn.to_k.weight, dcae.encoder.down_blocks.3.1.attn.to_out.weight, dcae.encoder.down_blocks.3.1.attn.to_q.weight, dcae.encoder.down_blocks.3.1.attn.to_qkv_multiscale.0.proj_in.weight, dcae.encoder.down_blocks.3.1.attn.to_qkv_multiscale.0.proj_out.weight, dcae.encoder.down_blocks.3.1.attn.to_v.weight, dcae.encoder.down_blocks.3.1.conv_out.conv_depth.bias, dcae.encoder.down_blocks.3.1.conv_out.conv_depth.weight, dcae.encoder.down_blocks.3.1.conv_out.conv_inverted.bias, dcae.encoder.down_blocks.3.1.conv_out.conv_inverted.weight, dcae.encoder.down_blocks.3.1.conv_out.conv_point.weight, dcae.encoder.down_blocks.3.1.conv_out.norm.bias, dcae.encoder.down_blocks.3.1.conv_out.norm.weight, dcae.encoder.down_blocks.3.2.attn.norm_out.bias, dcae.encoder.down_blocks.3.2.attn.norm_out.weight, dcae.encoder.down_blocks.3.2.attn.to_k.weight, dcae.encoder.down_blocks.3.2.attn.to_out.weight, dcae.encoder.down_blocks.3.2.attn.to_q.weight, dcae.encoder.down_blocks.3.2.attn.to_qkv_multiscale.0.proj_in.weight, dcae.encoder.down_blocks.3.2.attn.to_qkv_multiscale.0.proj_out.weight, dcae.encoder.down_blocks.3.2.attn.to_v.weight, dcae.encoder.down_blocks.3.2.conv_out.conv_depth.bias, dcae.encoder.down_blocks.3.2.conv_out.conv_depth.weight, dcae.encoder.down_blocks.3.2.conv_out.conv_inverted.bias, dcae.encoder.down_blocks.3.2.conv_out.conv_inverted.weight, dcae.encoder.down_blocks.3.2.conv_out.conv_point.weight, dcae.encoder.down_blocks.3.2.conv_out.norm.bias, dcae.encoder.down_blocks.3.2.conv_out.norm.weight, vocoder.backbone.channel_layers.0.0.bias, vocoder.backbone.channel_layers.0.0.weight, vocoder.backbone.channel_layers.0.1.bias, vocoder.backbone.channel_layers.0.1.weight, vocoder.backbone.channel_layers.1.0.bias, vocoder.backbone.channel_layers.1.0.weight, vocoder.backbone.channel_layers.1.1.bias, vocoder.backbone.channel_layers.1.1.weight, vocoder.backbone.channel_layers.2.0.bias, vocoder.backbone.channel_layers.2.0.weight, vocoder.backbone.channel_layers.2.1.bias, vocoder.backbone.channel_layers.2.1.weight, vocoder.backbone.channel_layers.3.0.bias, vocoder.backbone.channel_layers.3.0.weight, vocoder.backbone.channel_layers.3.1.bias, vocoder.backbone.channel_layers.3.1.weight, vocoder.backbone.norm.bias, vocoder.backbone.norm.weight, vocoder.backbone.stages.0.0.dwconv.bias, vocoder.backbone.stages.0.0.dwconv.weight, vocoder.backbone.stages.0.0.gamma, vocoder.backbone.stages.0.0.norm.bias, vocoder.backbone.stages.0.0.norm.weight, vocoder.backbone.stages.0.0.pwconv1.bias, vocoder.backbone.stages.0.0.pwconv1.weight, vocoder.backbone.stages.0.0.pwconv2.bias, vocoder.backbone.stages.0.0.pwconv2.weight, vocoder.backbone.stages.0.1.dwconv.bias, vocoder.backbone.stages.0.1.dwconv.weight, vocoder.backbone.stages.0.1.gamma, vocoder.backbone.stages.0.1.norm.bias, vocoder.backbone.stages.0.1.norm.weight, vocoder.backbone.stages.0.1.pwconv1.bias, vocoder.backbone.stages.0.1.pwconv1.weight, vocoder.backbone.stages.0.1.pwconv2.bias, vocoder.backbone.stages.0.1.pwconv2.weight, vocoder.backbone.stages.0.2.dwconv.bias, vocoder.backbone.stages.0.2.dwconv.weight, vocoder.backbone.stages.0.2.gamma, vocoder.backbone.stages.0.2.norm.bias, vocoder.backbone.stages.0.2.norm.weight, vocoder.backbone.stages.0.2.pwconv1.bias, vocoder.backbone.stages.0.2.pwconv1.weight, vocoder.backbone.stages.0.2.pwconv2.bias, vocoder.backbone.stages.0.2.pwconv2.weight, vocoder.backbone.stages.1.0.dwconv.bias, vocoder.backbone.stages.1.0.dwconv.weight, vocoder.backbone.stages.1.0.gamma, vocoder.backbone.stages.1.0.norm.bias, vocoder.backbone.stages.1.0.norm.weight, vocoder.backbone.stages.1.0.pwconv1.bias, vocoder.backbone.stages.1.0.pwconv1.weight, vocoder.backbone.stages.1.0.pwconv2.bias, vocoder.backbone.stages.1.0.pwconv2.weight, vocoder.backbone.stages.1.1.dwconv.bias, vocoder.backbone.stages.1.1.dwconv.weight, vocoder.backbone.stages.1.1.gamma, vocoder.backbone.stages.1.1.norm.bias, vocoder.backbone.stages.1.1.norm.weight, vocoder.backbone.stages.1.1.pwconv1.bias, vocoder.backbone.stages.1.1.pwconv1.weight, vocoder.backbone.stages.1.1.pwconv2.bias, vocoder.backbone.stages.1.1.pwconv2.weight, vocoder.backbone.stages.1.2.dwconv.bias, vocoder.backbone.stages.1.2.dwconv.weight, vocoder.backbone.stages.1.2.gamma, vocoder.backbone.stages.1.2.norm.bias, vocoder.backbone.stages.1.2.norm.weight, vocoder.backbone.stages.1.2.pwconv1.bias, vocoder.backbone.stages.1.2.pwconv1.weight, vocoder.backbone.stages.1.2.pwconv2.bias, vocoder.backbone.stages.1.2.pwconv2.weight, vocoder.backbone.stages.2.0.dwconv.bias, vocoder.backbone.stages.2.0.dwconv.weight, vocoder.backbone.stages.2.0.gamma, vocoder.backbone.stages.2.0.norm.bias, vocoder.backbone.stages.2.0.norm.weight, vocoder.backbone.stages.2.0.pwconv1.bias, vocoder.backbone.stages.2.0.pwconv1.weight, vocoder.backbone.stages.2.0.pwconv2.bias, vocoder.backbone.stages.2.0.pwconv2.weight, vocoder.backbone.stages.2.1.dwconv.bias, vocoder.backbone.stages.2.1.dwconv.weight, vocoder.backbone.stages.2.1.gamma, vocoder.backbone.stages.2.1.norm.bias, vocoder.backbone.stages.2.1.norm.weight, vocoder.backbone.stages.2.1.pwconv1.bias, vocoder.backbone.stages.2.1.pwconv1.weight, vocoder.backbone.stages.2.1.pwconv2.bias, vocoder.backbone.stages.2.1.pwconv2.weight, vocoder.backbone.stages.2.2.dwconv.bias, vocoder.backbone.stages.2.2.dwconv.weight, vocoder.backbone.stages.2.2.gamma, vocoder.backbone.stages.2.2.norm.bias, vocoder.backbone.stages.2.2.norm.weight, vocoder.backbone.stages.2.2.pwconv1.bias, vocoder.backbone.stages.2.2.pwconv1.weight, vocoder.backbone.stages.2.2.pwconv2.bias, vocoder.backbone.stages.2.2.pwconv2.weight, vocoder.backbone.stages.2.3.dwconv.bias, vocoder.backbone.stages.2.3.dwconv.weight, vocoder.backbone.stages.2.3.gamma, vocoder.backbone.stages.2.3.norm.bias, vocoder.backbone.stages.2.3.norm.weight, vocoder.backbone.stages.2.3.pwconv1.bias, vocoder.backbone.stages.2.3.pwconv1.weight, vocoder.backbone.stages.2.3.pwconv2.bias, vocoder.backbone.stages.2.3.pwconv2.weight, vocoder.backbone.stages.2.4.dwconv.bias, vocoder.backbone.stages.2.4.dwconv.weight, vocoder.backbone.stages.2.4.gamma, vocoder.backbone.stages.2.4.norm.bias, vocoder.backbone.stages.2.4.norm.weight, vocoder.backbone.stages.2.4.pwconv1.bias, vocoder.backbone.stages.2.4.pwconv1.weight, vocoder.backbone.stages.2.4.pwconv2.bias, vocoder.backbone.stages.2.4.pwconv2.weight, vocoder.backbone.stages.2.5.dwconv.bias, vocoder.backbone.stages.2.5.dwconv.weight, vocoder.backbone.stages.2.5.gamma, vocoder.backbone.stages.2.5.norm.bias, vocoder.backbone.stages.2.5.norm.weight, vocoder.backbone.stages.2.5.pwconv1.bias, vocoder.backbone.stages.2.5.pwconv1.weight, vocoder.backbone.stages.2.5.pwconv2.bias, vocoder.backbone.stages.2.5.pwconv2.weight, vocoder.backbone.stages.2.6.dwconv.bias, vocoder.backbone.stages.2.6.dwconv.weight, vocoder.backbone.stages.2.6.gamma, vocoder.backbone.stages.2.6.norm.bias, vocoder.backbone.stages.2.6.norm.weight, vocoder.backbone.stages.2.6.pwconv1.bias, vocoder.backbone.stages.2.6.pwconv1.weight, vocoder.backbone.stages.2.6.pwconv2.bias, vocoder.backbone.stages.2.6.pwconv2.weight, vocoder.backbone.stages.2.7.dwconv.bias, vocoder.backbone.stages.2.7.dwconv.weight, vocoder.backbone.stages.2.7.gamma, vocoder.backbone.stages.2.7.norm.bias, vocoder.backbone.stages.2.7.norm.weight, vocoder.backbone.stages.2.7.pwconv1.bias, vocoder.backbone.stages.2.7.pwconv1.weight, vocoder.backbone.stages.2.7.pwconv2.bias, vocoder.backbone.stages.2.7.pwconv2.weight, vocoder.backbone.stages.2.8.dwconv.bias, vocoder.backbone.stages.2.8.dwconv.weight, vocoder.backbone.stages.2.8.gamma, vocoder.backbone.stages.2.8.norm.bias, vocoder.backbone.stages.2.8.norm.weight, vocoder.backbone.stages.2.8.pwconv1.bias, vocoder.backbone.stages.2.8.pwconv1.weight, vocoder.backbone.stages.2.8.pwconv2.bias, vocoder.backbone.stages.2.8.pwconv2.weight, vocoder.backbone.stages.3.0.dwconv.bias, vocoder.backbone.stages.3.0.dwconv.weight, vocoder.backbone.stages.3.0.gamma, vocoder.backbone.stages.3.0.norm.bias, vocoder.backbone.stages.3.0.norm.weight, vocoder.backbone.stages.3.0.pwconv1.bias, vocoder.backbone.stages.3.0.pwconv1.weight, vocoder.backbone.stages.3.0.pwconv2.bias, vocoder.backbone.stages.3.0.pwconv2.weight, vocoder.backbone.stages.3.1.dwconv.bias, vocoder.backbone.stages.3.1.dwconv.weight, vocoder.backbone.stages.3.1.gamma, vocoder.backbone.stages.3.1.norm.bias, vocoder.backbone.stages.3.1.norm.weight, vocoder.backbone.stages.3.1.pwconv1.bias, vocoder.backbone.stages.3.1.pwconv1.weight, vocoder.backbone.stages.3.1.pwconv2.bias, vocoder.backbone.stages.3.1.pwconv2.weight, vocoder.backbone.stages.3.2.dwconv.bias, vocoder.backbone.stages.3.2.dwconv.weight, vocoder.backbone.stages.3.2.gamma, vocoder.backbone.stages.3.2.norm.bias, vocoder.backbone.stages.3.2.norm.weight, vocoder.backbone.stages.3.2.pwconv1.bias, vocoder.backbone.stages.3.2.pwconv1.weight, vocoder.backbone.stages.3.2.pwconv2.bias, vocoder.backbone.stages.3.2.pwconv2.weight, vocoder.head.conv_post.bias, vocoder.head.conv_post.weight_g, vocoder.head.conv_post.weight_v, vocoder.head.conv_pre.bias, vocoder.head.conv_pre.weight_g, vocoder.head.conv_pre.weight_v, vocoder.head.resblocks.0.convs1.0.bias, vocoder.head.resblocks.0.convs1.0.weight_g, vocoder.head.resblocks.0.convs1.0.weight_v, vocoder.head.resblocks.0.convs1.1.bias, vocoder.head.resblocks.0.convs1.1.weight_g, vocoder.head.resblocks.0.convs1.1.weight_v, vocoder.head.resblocks.0.convs1.2.bias, vocoder.head.resblocks.0.convs1.2.weight_g, vocoder.head.resblocks.0.convs1.2.weight_v, vocoder.head.resblocks.0.convs2.0.bias, vocoder.head.resblocks.0.convs2.0.weight_g, vocoder.head.resblocks.0.convs2.0.weight_v, vocoder.head.resblocks.0.convs2.1.bias, vocoder.head.resblocks.0.convs2.1.weight_g, vocoder.head.resblocks.0.convs2.1.weight_v, vocoder.head.resblocks.0.convs2.2.bias, vocoder.head.resblocks.0.convs2.2.weight_g, vocoder.head.resblocks.0.convs2.2.weight_v, vocoder.head.resblocks.1.convs1.0.bias, vocoder.head.resblocks.1.convs1.0.weight_g, vocoder.head.resblocks.1.convs1.0.weight_v, vocoder.head.resblocks.1.convs1.1.bias, vocoder.head.resblocks.1.convs1.1.weight_g, vocoder.head.resblocks.1.convs1.1.weight_v, vocoder.head.resblocks.1.convs1.2.bias, vocoder.head.resblocks.1.convs1.2.weight_g, vocoder.head.resblocks.1.convs1.2.weight_v, vocoder.head.resblocks.1.convs2.0.bias, vocoder.head.resblocks.1.convs2.0.weight_g, vocoder.head.resblocks.1.convs2.0.weight_v, vocoder.head.resblocks.1.convs2.1.bias, vocoder.head.resblocks.1.convs2.1.weight_g, vocoder.head.resblocks.1.convs2.1.weight_v, vocoder.head.resblocks.1.convs2.2.bias, vocoder.head.resblocks.1.convs2.2.weight_g, vocoder.head.resblocks.1.convs2.2.weight_v, vocoder.head.resblocks.10.convs1.0.bias, vocoder.head.resblocks.10.convs1.0.weight_g, vocoder.head.resblocks.10.convs1.0.weight_v, vocoder.head.resblocks.10.convs1.1.bias, vocoder.head.resblocks.10.convs1.1.weight_g, vocoder.head.resblocks.10.convs1.1.weight_v, vocoder.head.resblocks.10.convs1.2.bias, vocoder.head.resblocks.10.convs1.2.weight_g, vocoder.head.resblocks.10.convs1.2.weight_v, vocoder.head.resblocks.10.convs2.0.bias, vocoder.head.resblocks.10.convs2.0.weight_g, vocoder.head.resblocks.10.convs2.0.weight_v, vocoder.head.resblocks.10.convs2.1.bias, vocoder.head.resblocks.10.convs2.1.weight_g, vocoder.head.resblocks.10.convs2.1.weight_v, vocoder.head.resblocks.10.convs2.2.bias, vocoder.head.resblocks.10.convs2.2.weight_g, vocoder.head.resblocks.10.convs2.2.weight_v, vocoder.head.resblocks.11.convs1.0.bias, vocoder.head.resblocks.11.convs1.0.weight_g, vocoder.head.resblocks.11.convs1.0.weight_v, vocoder.head.resblocks.11.convs1.1.bias, vocoder.head.resblocks.11.convs1.1.weight_g, vocoder.head.resblocks.11.convs1.1.weight_v, vocoder.head.resblocks.11.convs1.2.bias, vocoder.head.resblocks.11.convs1.2.weight_g, vocoder.head.resblocks.11.convs1.2.weight_v, vocoder.head.resblocks.11.convs2.0.bias, vocoder.head.resblocks.11.convs2.0.weight_g, vocoder.head.resblocks.11.convs2.0.weight_v, vocoder.head.resblocks.11.convs2.1.bias, vocoder.head.resblocks.11.convs2.1.weight_g, vocoder.head.resblocks.11.convs2.1.weight_v, vocoder.head.resblocks.11.convs2.2.bias, vocoder.head.resblocks.11.convs2.2.weight_g, vocoder.head.resblocks.11.convs2.2.weight_v, vocoder.head.resblocks.12.convs1.0.bias, vocoder.head.resblocks.12.convs1.0.weight_g, vocoder.head.resblocks.12.convs1.0.weight_v, vocoder.head.resblocks.12.convs1.1.bias, vocoder.head.resblocks.12.convs1.1.weight_g, vocoder.head.resblocks.12.convs1.1.weight_v, vocoder.head.resblocks.12.convs1.2.bias, vocoder.head.resblocks.12.convs1.2.weight_g, vocoder.head.resblocks.12.convs1.2.weight_v, vocoder.head.resblocks.12.convs2.0.bias, vocoder.head.resblocks.12.convs2.0.weight_g, vocoder.head.resblocks.12.convs2.0.weight_v, vocoder.head.resblocks.12.convs2.1.bias, vocoder.head.resblocks.12.convs2.1.weight_g, vocoder.head.resblocks.12.convs2.1.weight_v, vocoder.head.resblocks.12.convs2.2.bias, vocoder.head.resblocks.12.convs2.2.weight_g, vocoder.head.resblocks.12.convs2.2.weight_v, vocoder.head.resblocks.13.convs1.0.bias, vocoder.head.resblocks.13.convs1.0.weight_g, vocoder.head.resblocks.13.convs1.0.weight_v, vocoder.head.resblocks.13.convs1.1.bias, vocoder.head.resblocks.13.convs1.1.weight_g, vocoder.head.resblocks.13.convs1.1.weight_v, vocoder.head.resblocks.13.convs1.2.bias, vocoder.head.resblocks.13.convs1.2.weight_g, vocoder.head.resblocks.13.convs1.2.weight_v, vocoder.head.resblocks.13.convs2.0.bias, vocoder.head.resblocks.13.convs2.0.weight_g, vocoder.head.resblocks.13.convs2.0.weight_v, vocoder.head.resblocks.13.convs2.1.bias, vocoder.head.resblocks.13.convs2.1.weight_g, vocoder.head.resblocks.13.convs2.1.weight_v, vocoder.head.resblocks.13.convs2.2.bias, vocoder.head.resblocks.13.convs2.2.weight_g, vocoder.head.resblocks.13.convs2.2.weight_v, vocoder.head.resblocks.14.convs1.0.bias, vocoder.head.resblocks.14.convs1.0.weight_g, vocoder.head.resblocks.14.convs1.0.weight_v, vocoder.head.resblocks.14.convs1.1.bias, vocoder.head.resblocks.14.convs1.1.weight_g, vocoder.head.resblocks.14.convs1.1.weight_v, vocoder.head.resblocks.14.convs1.2.bias, vocoder.head.resblocks.14.convs1.2.weight_g, vocoder.head.resblocks.14.convs1.2.weight_v, vocoder.head.resblocks.14.convs2.0.bias, vocoder.head.resblocks.14.convs2.0.weight_g, vocoder.head.resblocks.14.convs2.0.weight_v, vocoder.head.resblocks.14.convs2.1.bias, vocoder.head.resblocks.14.convs2.1.weight_g, vocoder.head.resblocks.14.convs2.1.weight_v, vocoder.head.resblocks.14.convs2.2.bias, vocoder.head.resblocks.14.convs2.2.weight_g, vocoder.head.resblocks.14.convs2.2.weight_v, vocoder.head.resblocks.15.convs1.0.bias, vocoder.head.resblocks.15.convs1.0.weight_g, vocoder.head.resblocks.15.convs1.0.weight_v, vocoder.head.resblocks.15.convs1.1.bias, vocoder.head.resblocks.15.convs1.1.weight_g, vocoder.head.resblocks.15.convs1.1.weight_v, vocoder.head.resblocks.15.convs1.2.bias, vocoder.head.resblocks.15.convs1.2.weight_g, vocoder.head.resblocks.15.convs1.2.weight_v, vocoder.head.resblocks.15.convs2.0.bias, vocoder.head.resblocks.15.convs2.0.weight_g, vocoder.head.resblocks.15.convs2.0.weight_v, vocoder.head.resblocks.15.convs2.1.bias, vocoder.head.resblocks.15.convs2.1.weight_g, vocoder.head.resblocks.15.convs2.1.weight_v, vocoder.head.resblocks.15.convs2.2.bias, vocoder.head.resblocks.15.convs2.2.weight_g, vocoder.head.resblocks.15.convs2.2.weight_v, vocoder.head.resblocks.16.convs1.0.bias, vocoder.head.resblocks.16.convs1.0.weight_g, vocoder.head.resblocks.16.convs1.0.weight_v, vocoder.head.resblocks.16.convs1.1.bias, vocoder.head.resblocks.16.convs1.1.weight_g, vocoder.head.resblocks.16.convs1.1.weight_v, vocoder.head.resblocks.16.convs1.2.bias, vocoder.head.resblocks.16.convs1.2.weight_g, vocoder.head.resblocks.16.convs1.2.weight_v, vocoder.head.resblocks.16.convs2.0.bias, vocoder.head.resblocks.16.convs2.0.weight_g, vocoder.head.resblocks.16.convs2.0.weight_v, vocoder.head.resblocks.16.convs2.1.bias, vocoder.head.resblocks.16.convs2.1.weight_g, vocoder.head.resblocks.16.convs2.1.weight_v, vocoder.head.resblocks.16.convs2.2.bias, vocoder.head.resblocks.16.convs2.2.weight_g, vocoder.head.resblocks.16.convs2.2.weight_v, vocoder.head.resblocks.17.convs1.0.bias, vocoder.head.resblocks.17.convs1.0.weight_g, vocoder.head.resblocks.17.convs1.0.weight_v, vocoder.head.resblocks.17.convs1.1.bias, vocoder.head.resblocks.17.convs1.1.weight_g, vocoder.head.resblocks.17.convs1.1.weight_v, vocoder.head.resblocks.17.convs1.2.bias, vocoder.head.resblocks.17.convs1.2.weight_g, vocoder.head.resblocks.17.convs1.2.weight_v, vocoder.head.resblocks.17.convs2.0.bias, vocoder.head.resblocks.17.convs2.0.weight_g, vocoder.head.resblocks.17.convs2.0.weight_v, vocoder.head.resblocks.17.convs2.1.bias, vocoder.head.resblocks.17.convs2.1.weight_g, vocoder.head.resblocks.17.convs2.1.weight_v, vocoder.head.resblocks.17.convs2.2.bias, vocoder.head.resblocks.17.convs2.2.weight_g, vocoder.head.resblocks.17.convs2.2.weight_v, vocoder.head.resblocks.18.convs1.0.bias, vocoder.head.resblocks.18.convs1.0.weight_g, vocoder.head.resblocks.18.convs1.0.weight_v, vocoder.head.resblocks.18.convs1.1.bias, vocoder.head.resblocks.18.convs1.1.weight_g, vocoder.head.resblocks.18.convs1.1.weight_v, vocoder.head.resblocks.18.convs1.2.bias, vocoder.head.resblocks.18.convs1.2.weight_g, vocoder.head.resblocks.18.convs1.2.weight_v, vocoder.head.resblocks.18.convs2.0.bias, vocoder.head.resblocks.18.convs2.0.weight_g, vocoder.head.resblocks.18.convs2.0.weight_v, vocoder.head.resblocks.18.convs2.1.bias, vocoder.head.resblocks.18.convs2.1.weight_g, vocoder.head.resblocks.18.convs2.1.weight_v, vocoder.head.resblocks.18.convs2.2.bias, vocoder.head.resblocks.18.convs2.2.weight_g, vocoder.head.resblocks.18.convs2.2.weight_v, vocoder.head.resblocks.19.convs1.0.bias, vocoder.head.resblocks.19.convs1.0.weight_g, vocoder.head.resblocks.19.convs1.0.weight_v, vocoder.head.resblocks.19.convs1.1.bias, vocoder.head.resblocks.19.convs1.1.weight_g, vocoder.head.resblocks.19.convs1.1.weight_v, vocoder.head.resblocks.19.convs1.2.bias, vocoder.head.resblocks.19.convs1.2.weight_g, vocoder.head.resblocks.19.convs1.2.weight_v, vocoder.head.resblocks.19.convs2.0.bias, vocoder.head.resblocks.19.convs2.0.weight_g, vocoder.head.resblocks.19.convs2.0.weight_v, vocoder.head.resblocks.19.convs2.1.bias, vocoder.head.resblocks.19.convs2.1.weight_g, vocoder.head.resblocks.19.convs2.1.weight_v, vocoder.head.resblocks.19.convs2.2.bias, vocoder.head.resblocks.19.convs2.2.weight_g, vocoder.head.resblocks.19.convs2.2.weight_v, vocoder.head.resblocks.2.convs1.0.bias, vocoder.head.resblocks.2.convs1.0.weight_g, vocoder.head.resblocks.2.convs1.0.weight_v, vocoder.head.resblocks.2.convs1.1.bias, vocoder.head.resblocks.2.convs1.1.weight_g, vocoder.head.resblocks.2.convs1.1.weight_v, vocoder.head.resblocks.2.convs1.2.bias, vocoder.head.resblocks.2.convs1.2.weight_g, vocoder.head.resblocks.2.convs1.2.weight_v, vocoder.head.resblocks.2.convs2.0.bias, vocoder.head.resblocks.2.convs2.0.weight_g, vocoder.head.resblocks.2.convs2.0.weight_v, vocoder.head.resblocks.2.convs2.1.bias, vocoder.head.resblocks.2.convs2.1.weight_g, vocoder.head.resblocks.2.convs2.1.weight_v, vocoder.head.resblocks.2.convs2.2.bias, vocoder.head.resblocks.2.convs2.2.weight_g, vocoder.head.resblocks.2.convs2.2.weight_v, vocoder.head.resblocks.20.convs1.0.bias, vocoder.head.resblocks.20.convs1.0.weight_g, vocoder.head.resblocks.20.convs1.0.weight_v, vocoder.head.resblocks.20.convs1.1.bias, vocoder.head.resblocks.20.convs1.1.weight_g, vocoder.head.resblocks.20.convs1.1.weight_v, vocoder.head.resblocks.20.convs1.2.bias, vocoder.head.resblocks.20.convs1.2.weight_g, vocoder.head.resblocks.20.convs1.2.weight_v, vocoder.head.resblocks.20.convs2.0.bias, vocoder.head.resblocks.20.convs2.0.weight_g, vocoder.head.resblocks.20.convs2.0.weight_v, vocoder.head.resblocks.20.convs2.1.bias, vocoder.head.resblocks.20.convs2.1.weight_g, vocoder.head.resblocks.20.convs2.1.weight_v, vocoder.head.resblocks.20.convs2.2.bias, vocoder.head.resblocks.20.convs2.2.weight_g, vocoder.head.resblocks.20.convs2.2.weight_v, vocoder.head.resblocks.21.convs1.0.bias, vocoder.head.resblocks.21.convs1.0.weight_g, vocoder.head.resblocks.21.convs1.0.weight_v, vocoder.head.resblocks.21.convs1.1.bias, vocoder.head.resblocks.21.convs1.1.weight_g, vocoder.head.resblocks.21.convs1.1.weight_v, vocoder.head.resblocks.21.convs1.2.bias, vocoder.head.resblocks.21.convs1.2.weight_g, vocoder.head.resblocks.21.convs1.2.weight_v, vocoder.head.resblocks.21.convs2.0.bias, vocoder.head.resblocks.21.convs2.0.weight_g, vocoder.head.resblocks.21.convs2.0.weight_v, vocoder.head.resblocks.21.convs2.1.bias, vocoder.head.resblocks.21.convs2.1.weight_g, vocoder.head.resblocks.21.convs2.1.weight_v, vocoder.head.resblocks.21.convs2.2.bias, vocoder.head.resblocks.21.convs2.2.weight_g, vocoder.head.resblocks.21.convs2.2.weight_v, vocoder.head.resblocks.22.convs1.0.bias, vocoder.head.resblocks.22.convs1.0.weight_g, vocoder.head.resblocks.22.convs1.0.weight_v, vocoder.head.resblocks.22.convs1.1.bias, vocoder.head.resblocks.22.convs1.1.weight_g, vocoder.head.resblocks.22.convs1.1.weight_v, vocoder.head.resblocks.22.convs1.2.bias, vocoder.head.resblocks.22.convs1.2.weight_g, vocoder.head.resblocks.22.convs1.2.weight_v, vocoder.head.resblocks.22.convs2.0.bias, vocoder.head.resblocks.22.convs2.0.weight_g, vocoder.head.resblocks.22.convs2.0.weight_v, vocoder.head.resblocks.22.convs2.1.bias, vocoder.head.resblocks.22.convs2.1.weight_g, vocoder.head.resblocks.22.convs2.1.weight_v, vocoder.head.resblocks.22.convs2.2.bias, vocoder.head.resblocks.22.convs2.2.weight_g, vocoder.head.resblocks.22.convs2.2.weight_v, vocoder.head.resblocks.23.convs1.0.bias, vocoder.head.resblocks.23.convs1.0.weight_g, vocoder.head.resblocks.23.convs1.0.weight_v, vocoder.head.resblocks.23.convs1.1.bias, vocoder.head.resblocks.23.convs1.1.weight_g, vocoder.head.resblocks.23.convs1.1.weight_v, vocoder.head.resblocks.23.convs1.2.bias, vocoder.head.resblocks.23.convs1.2.weight_g, vocoder.head.resblocks.23.convs1.2.weight_v, vocoder.head.resblocks.23.convs2.0.bias, vocoder.head.resblocks.23.convs2.0.weight_g, vocoder.head.resblocks.23.convs2.0.weight_v, vocoder.head.resblocks.23.convs2.1.bias, vocoder.head.resblocks.23.convs2.1.weight_g, vocoder.head.resblocks.23.convs2.1.weight_v, vocoder.head.resblocks.23.convs2.2.bias, vocoder.head.resblocks.23.convs2.2.weight_g, vocoder.head.resblocks.23.convs2.2.weight_v, vocoder.head.resblocks.24.convs1.0.bias, vocoder.head.resblocks.24.convs1.0.weight_g, vocoder.head.resblocks.24.convs1.0.weight_v, vocoder.head.resblocks.24.convs1.1.bias, vocoder.head.resblocks.24.convs1.1.weight_g, vocoder.head.resblocks.24.convs1.1.weight_v, vocoder.head.resblocks.24.convs1.2.bias, vocoder.head.resblocks.24.convs1.2.weight_g, vocoder.head.resblocks.24.convs1.2.weight_v, vocoder.head.resblocks.24.convs2.0.bias, vocoder.head.resblocks.24.convs2.0.weight_g, vocoder.head.resblocks.24.convs2.0.weight_v, vocoder.head.resblocks.24.convs2.1.bias, vocoder.head.resblocks.24.convs2.1.weight_g, vocoder.head.resblocks.24.convs2.1.weight_v, vocoder.head.resblocks.24.convs2.2.bias, vocoder.head.resblocks.24.convs2.2.weight_g, vocoder.head.resblocks.24.convs2.2.weight_v, vocoder.head.resblocks.25.convs1.0.bias, vocoder.head.resblocks.25.convs1.0.weight_g, vocoder.head.resblocks.25.convs1.0.weight_v, vocoder.head.resblocks.25.convs1.1.bias, vocoder.head.resblocks.25.convs1.1.weight_g, vocoder.head.resblocks.25.convs1.1.weight_v, vocoder.head.resblocks.25.convs1.2.bias, vocoder.head.resblocks.25.convs1.2.weight_g, vocoder.head.resblocks.25.convs1.2.weight_v, vocoder.head.resblocks.25.convs2.0.bias, vocoder.head.resblocks.25.convs2.0.weight_g, vocoder.head.resblocks.25.convs2.0.weight_v, vocoder.head.resblocks.25.convs2.1.bias, vocoder.head.resblocks.25.convs2.1.weight_g, vocoder.head.resblocks.25.convs2.1.weight_v, vocoder.head.resblocks.25.convs2.2.bias, vocoder.head.resblocks.25.convs2.2.weight_g, vocoder.head.resblocks.25.convs2.2.weight_v, vocoder.head.resblocks.26.convs1.0.bias, vocoder.head.resblocks.26.convs1.0.weight_g, vocoder.head.resblocks.26.convs1.0.weight_v, vocoder.head.resblocks.26.convs1.1.bias, vocoder.head.resblocks.26.convs1.1.weight_g, vocoder.head.resblocks.26.convs1.1.weight_v, vocoder.head.resblocks.26.convs1.2.bias, vocoder.head.resblocks.26.convs1.2.weight_g, vocoder.head.resblocks.26.convs1.2.weight_v, vocoder.head.resblocks.26.convs2.0.bias, vocoder.head.resblocks.26.convs2.0.weight_g, vocoder.head.resblocks.26.convs2.0.weight_v, vocoder.head.resblocks.26.convs2.1.bias, vocoder.head.resblocks.26.convs2.1.weight_g, vocoder.head.resblocks.26.convs2.1.weight_v, vocoder.head.resblocks.26.convs2.2.bias, vocoder.head.resblocks.26.convs2.2.weight_g, vocoder.head.resblocks.26.convs2.2.weight_v, vocoder.head.resblocks.27.convs1.0.bias, vocoder.head.resblocks.27.convs1.0.weight_g, vocoder.head.resblocks.27.convs1.0.weight_v, vocoder.head.resblocks.27.convs1.1.bias, vocoder.head.resblocks.27.convs1.1.weight_g, vocoder.head.resblocks.27.convs1.1.weight_v, vocoder.head.resblocks.27.convs1.2.bias, vocoder.head.resblocks.27.convs1.2.weight_g, vocoder.head.resblocks.27.convs1.2.weight_v, vocoder.head.resblocks.27.convs2.0.bias, vocoder.head.resblocks.27.convs2.0.weight_g, vocoder.head.resblocks.27.convs2.0.weight_v, vocoder.head.resblocks.27.convs2.1.bias, vocoder.head.resblocks.27.convs2.1.weight_g, vocoder.head.resblocks.27.convs2.1.weight_v, vocoder.head.resblocks.27.convs2.2.bias, vocoder.head.resblocks.27.convs2.2.weight_g, vocoder.head.resblocks.27.convs2.2.weight_v, vocoder.head.resblocks.3.convs1.0.bias, vocoder.head.resblocks.3.convs1.0.weight_g, vocoder.head.resblocks.3.convs1.0.weight_v, vocoder.head.resblocks.3.convs1.1.bias, vocoder.head.resblocks.3.convs1.1.weight_g, vocoder.head.resblocks.3.convs1.1.weight_v, vocoder.head.resblocks.3.convs1.2.bias, vocoder.head.resblocks.3.convs1.2.weight_g, vocoder.head.resblocks.3.convs1.2.weight_v, vocoder.head.resblocks.3.convs2.0.bias, vocoder.head.resblocks.3.convs2.0.weight_g, vocoder.head.resblocks.3.convs2.0.weight_v, vocoder.head.resblocks.3.convs2.1.bias, vocoder.head.resblocks.3.convs2.1.weight_g, vocoder.head.resblocks.3.convs2.1.weight_v, vocoder.head.resblocks.3.convs2.2.bias, vocoder.head.resblocks.3.convs2.2.weight_g, vocoder.head.resblocks.3.convs2.2.weight_v, vocoder.head.resblocks.4.convs1.0.bias, vocoder.head.resblocks.4.convs1.0.weight_g, vocoder.head.resblocks.4.convs1.0.weight_v, vocoder.head.resblocks.4.convs1.1.bias, vocoder.head.resblocks.4.convs1.1.weight_g, vocoder.head.resblocks.4.convs1.1.weight_v, vocoder.head.resblocks.4.convs1.2.bias, vocoder.head.resblocks.4.convs1.2.weight_g, vocoder.head.resblocks.4.convs1.2.weight_v, vocoder.head.resblocks.4.convs2.0.bias, vocoder.head.resblocks.4.convs2.0.weight_g, vocoder.head.resblocks.4.convs2.0.weight_v, vocoder.head.resblocks.4.convs2.1.bias, vocoder.head.resblocks.4.convs2.1.weight_g, vocoder.head.resblocks.4.convs2.1.weight_v, vocoder.head.resblocks.4.convs2.2.bias, vocoder.head.resblocks.4.convs2.2.weight_g, vocoder.head.resblocks.4.convs2.2.weight_v, vocoder.head.resblocks.5.convs1.0.bias, vocoder.head.resblocks.5.convs1.0.weight_g, vocoder.head.resblocks.5.convs1.0.weight_v, vocoder.head.resblocks.5.convs1.1.bias, vocoder.head.resblocks.5.convs1.1.weight_g, vocoder.head.resblocks.5.convs1.1.weight_v, vocoder.head.resblocks.5.convs1.2.bias, vocoder.head.resblocks.5.convs1.2.weight_g, vocoder.head.resblocks.5.convs1.2.weight_v, vocoder.head.resblocks.5.convs2.0.bias, vocoder.head.resblocks.5.convs2.0.weight_g, vocoder.head.resblocks.5.convs2.0.weight_v, vocoder.head.resblocks.5.convs2.1.bias, vocoder.head.resblocks.5.convs2.1.weight_g, vocoder.head.resblocks.5.convs2.1.weight_v, vocoder.head.resblocks.5.convs2.2.bias, vocoder.head.resblocks.5.convs2.2.weight_g, vocoder.head.resblocks.5.convs2.2.weight_v, vocoder.head.resblocks.6.convs1.0.bias, vocoder.head.resblocks.6.convs1.0.weight_g, vocoder.head.resblocks.6.convs1.0.weight_v, vocoder.head.resblocks.6.convs1.1.bias, vocoder.head.resblocks.6.convs1.1.weight_g, vocoder.head.resblocks.6.convs1.1.weight_v, vocoder.head.resblocks.6.convs1.2.bias, vocoder.head.resblocks.6.convs1.2.weight_g, vocoder.head.resblocks.6.convs1.2.weight_v, vocoder.head.resblocks.6.convs2.0.bias, vocoder.head.resblocks.6.convs2.0.weight_g, vocoder.head.resblocks.6.convs2.0.weight_v, vocoder.head.resblocks.6.convs2.1.bias, vocoder.head.resblocks.6.convs2.1.weight_g, vocoder.head.resblocks.6.convs2.1.weight_v, vocoder.head.resblocks.6.convs2.2.bias, vocoder.head.resblocks.6.convs2.2.weight_g, vocoder.head.resblocks.6.convs2.2.weight_v, vocoder.head.resblocks.7.convs1.0.bias, vocoder.head.resblocks.7.convs1.0.weight_g, vocoder.head.resblocks.7.convs1.0.weight_v, vocoder.head.resblocks.7.convs1.1.bias, vocoder.head.resblocks.7.convs1.1.weight_g, vocoder.head.resblocks.7.convs1.1.weight_v, vocoder.head.resblocks.7.convs1.2.bias, vocoder.head.resblocks.7.convs1.2.weight_g, vocoder.head.resblocks.7.convs1.2.weight_v, vocoder.head.resblocks.7.convs2.0.bias, vocoder.head.resblocks.7.convs2.0.weight_g, vocoder.head.resblocks.7.convs2.0.weight_v, vocoder.head.resblocks.7.convs2.1.bias, vocoder.head.resblocks.7.convs2.1.weight_g, vocoder.head.resblocks.7.convs2.1.weight_v, vocoder.head.resblocks.7.convs2.2.bias, vocoder.head.resblocks.7.convs2.2.weight_g, vocoder.head.resblocks.7.convs2.2.weight_v, vocoder.head.resblocks.8.convs1.0.bias, vocoder.head.resblocks.8.convs1.0.weight_g, vocoder.head.resblocks.8.convs1.0.weight_v, vocoder.head.resblocks.8.convs1.1.bias, vocoder.head.resblocks.8.convs1.1.weight_g, vocoder.head.resblocks.8.convs1.1.weight_v, vocoder.head.resblocks.8.convs1.2.bias, vocoder.head.resblocks.8.convs1.2.weight_g, vocoder.head.resblocks.8.convs1.2.weight_v, vocoder.head.resblocks.8.convs2.0.bias, vocoder.head.resblocks.8.convs2.0.weight_g, vocoder.head.resblocks.8.convs2.0.weight_v, vocoder.head.resblocks.8.convs2.1.bias, vocoder.head.resblocks.8.convs2.1.weight_g, vocoder.head.resblocks.8.convs2.1.weight_v, vocoder.head.resblocks.8.convs2.2.bias, vocoder.head.resblocks.8.convs2.2.weight_g, vocoder.head.resblocks.8.convs2.2.weight_v, vocoder.head.resblocks.9.convs1.0.bias, vocoder.head.resblocks.9.convs1.0.weight_g, vocoder.head.resblocks.9.convs1.0.weight_v, vocoder.head.resblocks.9.convs1.1.bias, vocoder.head.resblocks.9.convs1.1.weight_g, vocoder.head.resblocks.9.convs1.1.weight_v, vocoder.head.resblocks.9.convs1.2.bias, vocoder.head.resblocks.9.convs1.2.weight_g, vocoder.head.resblocks.9.convs1.2.weight_v, vocoder.head.resblocks.9.convs2.0.bias, vocoder.head.resblocks.9.convs2.0.weight_g, vocoder.head.resblocks.9.convs2.0.weight_v, vocoder.head.resblocks.9.convs2.1.bias, vocoder.head.resblocks.9.convs2.1.weight_g, vocoder.head.resblocks.9.convs2.1.weight_v, vocoder.head.resblocks.9.convs2.2.bias, vocoder.head.resblocks.9.convs2.2.weight_g, vocoder.head.resblocks.9.convs2.2.weight_v, vocoder.head.ups.0.bias, vocoder.head.ups.0.weight_g, vocoder.head.ups.0.weight_v, vocoder.head.ups.1.bias, vocoder.head.ups.1.weight_g, vocoder.head.ups.1.weight_v, vocoder.head.ups.2.bias, vocoder.head.ups.2.weight_g, vocoder.head.ups.2.weight_v, vocoder.head.ups.3.bias, vocoder.head.ups.3.weight_g, vocoder.head.ups.3.weight_v, vocoder.head.ups.4.bias, vocoder.head.ups.4.weight_g, vocoder.head.ups.4.weight_v, vocoder.head.ups.5.bias, vocoder.head.ups.5.weight_g, vocoder.head.ups.5.weight_v, vocoder.head.ups.6.bias, vocoder.head.ups.6.weight_g, vocoder.head.ups.6.weight_v, vocoder.mel_transform.mel_scale.fb, vocoder.mel_transform.spectrogram.window']\n"
     ]
    }
   ],
   "source": [
    "music_dcae = MusicDCAE.from_pretrained(\"./checkpoints/music_dcae_vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MusicDCAE(\n",
       "  (dcae): AutoencoderDC(\n",
       "    (encoder): Encoder(\n",
       "      (conv_in): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (down_blocks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): DCDownBlock2d(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): DCDownBlock2d(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (3): DCDownBlock2d(\n",
       "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): EfficientViTBlock(\n",
       "            (attn): SanaMultiscaleLinearAttention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_qkv_multiscale): ModuleList(\n",
       "                (0): SanaMultiscaleAttentionProjection(\n",
       "                  (proj_in): Conv2d(3072, 3072, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=3072, bias=False)\n",
       "                  (proj_out): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=96, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (nonlinearity): ReLU()\n",
       "              (to_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm_out): RMSNorm()\n",
       "            )\n",
       "            (conv_out): GLUMBConv(\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_inverted): Conv2d(1024, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (conv_depth): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8192)\n",
       "              (conv_point): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): EfficientViTBlock(\n",
       "            (attn): SanaMultiscaleLinearAttention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_qkv_multiscale): ModuleList(\n",
       "                (0): SanaMultiscaleAttentionProjection(\n",
       "                  (proj_in): Conv2d(3072, 3072, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=3072, bias=False)\n",
       "                  (proj_out): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=96, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (nonlinearity): ReLU()\n",
       "              (to_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm_out): RMSNorm()\n",
       "            )\n",
       "            (conv_out): GLUMBConv(\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_inverted): Conv2d(1024, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (conv_depth): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8192)\n",
       "              (conv_point): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): EfficientViTBlock(\n",
       "            (attn): SanaMultiscaleLinearAttention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_qkv_multiscale): ModuleList(\n",
       "                (0): SanaMultiscaleAttentionProjection(\n",
       "                  (proj_in): Conv2d(3072, 3072, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=3072, bias=False)\n",
       "                  (proj_out): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=96, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (nonlinearity): ReLU()\n",
       "              (to_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm_out): RMSNorm()\n",
       "            )\n",
       "            (conv_out): GLUMBConv(\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_inverted): Conv2d(1024, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (conv_depth): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8192)\n",
       "              (conv_point): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_out): Conv2d(1024, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (conv_in): Conv2d(8, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (up_blocks): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): DCUpBlock2d(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (3): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): DCUpBlock2d(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (3): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): DCUpBlock2d(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (1): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (2): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (3): ResBlock(\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): EfficientViTBlock(\n",
       "            (attn): SanaMultiscaleLinearAttention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_qkv_multiscale): ModuleList(\n",
       "                (0): SanaMultiscaleAttentionProjection(\n",
       "                  (proj_in): Conv2d(3072, 3072, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=3072, bias=False)\n",
       "                  (proj_out): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=96, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (nonlinearity): ReLU()\n",
       "              (to_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm_out): RMSNorm()\n",
       "            )\n",
       "            (conv_out): GLUMBConv(\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_inverted): Conv2d(1024, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (conv_depth): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8192)\n",
       "              (conv_point): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (1): EfficientViTBlock(\n",
       "            (attn): SanaMultiscaleLinearAttention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_qkv_multiscale): ModuleList(\n",
       "                (0): SanaMultiscaleAttentionProjection(\n",
       "                  (proj_in): Conv2d(3072, 3072, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=3072, bias=False)\n",
       "                  (proj_out): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=96, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (nonlinearity): ReLU()\n",
       "              (to_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm_out): RMSNorm()\n",
       "            )\n",
       "            (conv_out): GLUMBConv(\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_inverted): Conv2d(1024, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (conv_depth): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8192)\n",
       "              (conv_point): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (2): EfficientViTBlock(\n",
       "            (attn): SanaMultiscaleLinearAttention(\n",
       "              (to_q): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_k): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_v): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_qkv_multiscale): ModuleList(\n",
       "                (0): SanaMultiscaleAttentionProjection(\n",
       "                  (proj_in): Conv2d(3072, 3072, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=3072, bias=False)\n",
       "                  (proj_out): Conv2d(3072, 3072, kernel_size=(1, 1), stride=(1, 1), groups=96, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (nonlinearity): ReLU()\n",
       "              (to_out): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (norm_out): RMSNorm()\n",
       "            )\n",
       "            (conv_out): GLUMBConv(\n",
       "              (nonlinearity): SiLU()\n",
       "              (conv_inverted): Conv2d(1024, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (conv_depth): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8192)\n",
       "              (conv_point): Conv2d(4096, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): RMSNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_out): RMSNorm()\n",
       "      (conv_act): ReLU()\n",
       "      (conv_out): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (vocoder): ADaMoSHiFiGANV1(\n",
       "    (backbone): ConvNeXtEncoder(\n",
       "      (channel_layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), padding_mode=replicate)\n",
       "          (1): LayerNorm()\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm()\n",
       "          (1): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): LayerNorm()\n",
       "          (1): Conv1d(256, 384, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): LayerNorm()\n",
       "          (1): Conv1d(384, 512, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "      )\n",
       "      (stages): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), groups=128)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), groups=256)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), groups=256)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), groups=256)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (6): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (7): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (8): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(384, 384, kernel_size=(7,), stride=(1,), padding=(3,), groups=384)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), groups=512)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), groups=512)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): ConvNeXtBlock(\n",
       "            (dwconv): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), groups=512)\n",
       "            (norm): LayerNorm()\n",
       "            (pwconv1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (pwconv2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm()\n",
       "    )\n",
       "    (head): HiFiGANGenerator(\n",
       "      (conv_pre): Conv1d(512, 1024, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "      (noise_convs): ModuleList()\n",
       "      (ups): ModuleList(\n",
       "        (0): ConvTranspose1d(1024, 512, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (1): ConvTranspose1d(512, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n",
       "        (2): ConvTranspose1d(256, 128, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (3): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (4): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (5): ConvTranspose1d(32, 16, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "        (6): ConvTranspose1d(16, 8, kernel_size=(4,), stride=(2,), padding=(1,))\n",
       "      )\n",
       "      (resblocks): ModuleList(\n",
       "        (0): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (1): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (2): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(512, 512, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (3): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(512, 512, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(512, 512, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(512, 512, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(512, 512, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "        (4): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (5): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (6): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (7): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(256, 256, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(256, 256, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "        (8): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (9): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (10): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (11): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(128, 128, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(128, 128, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(128, 128, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(128, 128, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "        (12): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (13): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (14): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (15): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(64, 64, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(64, 64, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(64, 64, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(64, 64, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "        (16): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (17): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (18): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (19): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(32, 32, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(32, 32, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(32, 32, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(32, 32, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "        (20): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (21): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(16, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (22): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(16, 16, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (23): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(16, 16, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(16, 16, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(16, 16, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(16, 16, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "        (24): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "            (1): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "            (2): Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(8, 8, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          )\n",
       "        )\n",
       "        (25): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "            (1): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "            (2): Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(8, 8, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          )\n",
       "        )\n",
       "        (26): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(8, 8, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "            (1): Conv1d(8, 8, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "            (2): Conv1d(8, 8, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(8, 8, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          )\n",
       "        )\n",
       "        (27): ResBlock1(\n",
       "          (convs1): ModuleList(\n",
       "            (0): Conv1d(8, 8, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "            (1): Conv1d(8, 8, kernel_size=(13,), stride=(1,), padding=(18,), dilation=(3,))\n",
       "            (2): Conv1d(8, 8, kernel_size=(13,), stride=(1,), padding=(30,), dilation=(5,))\n",
       "          )\n",
       "          (convs2): ModuleList(\n",
       "            (0-2): 3 x Conv1d(8, 8, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (activation_post): SiLU(inplace=True)\n",
       "      (conv_post): Conv1d(8, 1, kernel_size=(13,), stride=(1,), padding=(6,))\n",
       "    )\n",
       "    (mel_transform): LogMelSpectrogram(\n",
       "      (spectrogram): LinearSpectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "  )\n",
       "  (resampler): Resample()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dcae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/sag_train/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "music_dcae = MusicDCAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_dcae.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "music_dcae = music_dcae.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_dcae.save_pretrained(\"checkpoints/music_dcae_vocoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sag_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
